{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandrill\n",
    "Authors: [RedSkittleFox](https://github.com/RedSkittleFox), [DJAltair](https://github.com/DJAltair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[blog] Using Nullmailer and Mandrill for your Ubuntu Linux server outboud mail:  http://bit.ly/ZjHOk7  #plone\n",
      "[blog] Using Postfix and free Mandrill email service for SMTP on Ubuntu Linux server:  http://bit.ly/11HmDZz  #plone\n",
      "@aalbertson There are several reasons emails go to spam. Mind submitting a request at http://help.mandrill.com  with additional details?\n",
      "@adrienneleigh I just switched it over to Mandrill, let's see if that improve the speed at which the emails are sent.\n",
      "@ankeshk +1 to @mailchimp We use MailChimp for marketing emails and their Mandrill app for txn emails... @sampad @abhijeetmk @hiway\n",
      "@biggoldring That error may occur if unsupported auth method used. Can you email us via http://help.mandrill.com  so we can get details?\n",
      "@BlueHayes mind sending us some details about your account via http://help.mandrill.com  ? Things look correct here but we may need some detail\n",
      "@cemsisman It can vary, but if sending really low volumes, may not be worth it. Can offer detail - submit request at http://help.mandrill.com \n",
      "@compactcode Have you checked out Mandrill (@mandrillapp)? It's a transactional email service that runs ... https://longreply.com/r/66c91ea4 \n",
      "@devongovett I'm using Mandrill, but been saving issues with some domains getting blocked with no bounce message. Very hard to debug.\n",
      "@devongovett Mandrill seems pretty cheap (by Mailchimp)\n",
      "@dzuelke The option to set up the Mandrill integration is only available to the account owner. If you ar... https://longreply.com/r/5c31a7d7 \n",
      "@dzuelke You should be able to login to the Mandrill account directly by using the same username and pas... https://longreply.com/r/2f58968b \n",
      "@edocr Can you send an email via http://help.mandrill.com with details about what page is crashing and where you're seeing issues?\n",
      "@eladlouni Et oui, Mandrill est moins cher, mais idem : ils ne permettent pas de gérer des listes de contact par exemple... @camj59\n",
      "@eladlouni La raison : Mandrill = Mailchimp, et ils ne veulent pas cannibaliser... @camj59\n",
      "@eladlouni Mandrill = pas de list management par ex. (ils ne veulent pas tuer Mailchimp qui est 30 à 40 fois plus cher ! cc @camj59\n",
      "@Elie__ @camj59 jparle de relai SMTP!1 million de mail chez mandrill / mois comparé à 1 million sur lite sendgrid y a pas photo avec mailjet\n",
      "@Elie__ @camj59 mandrill! Sendgrid! Sans parler d'amazon\n",
      "@EricCandino They're unfortunately not for sale but drop us a line via http://help.mandrill.com  and we'll see what we can find!\n",
      "@Flo_Rian Not seeing overall sending issues, but we'd want to look at your account - can you submit a request via http://help.mandrill.com  ?\n",
      "@frankioh @sinue mmm no. Mandrill y Sendgrid son + bien p/emails transaccionales. Mailchimp es + bien p/mkt. Admon de listas de dist. y tal.\n",
      "@gidogeek You can see what we've been working on and get a general idea of our plans at http://blog.mandrill.com  Updates posted every Friday!\n",
      "@guillaumepotier There are several reasons emails go to spam. Mind submitting a request at http://help.mandrill.com  with additional details?\n",
      "@icntmx Yep! We'd be glad to. Would you mind submitting a request at http://help.mandrill.com ?\n",
      "@JeremyWeir If you submit a request at http://help.mandrill.com , we'll get back to you with some ideas and help brainstorm if needed!\n",
      "@josscrowcroft Mind submitting a request via http://help.mandrill.com  with some additional details so we can help troubleshoot?\n",
      "@juanpabloaj Official clients have inline doc info but our support team can help with examples too - submit a request http://help.mandrill.com \n",
      "@kanonbulle No issues delivering to the Hotmail domain currently. Mind submitting a request at http://help.mandrill.com  w/ account details?\n",
      "@kennydude @devongovett Yeah, Mandrill is well worth a look.\n",
      "@kennyfraser Already cleaned up client & delisted IP, but #enginehosting support can share some alternatives like http://mandrill.com  too\n",
      "@khiger вот сервис http://mandrill.com/ \n",
      "@ljharb When I looked last year, Mandrill’s pricing and API was a bit confusing, but it now seems to have straightened out excellently.\n",
      "@mandrill Realised I did that about 5 seconds after hitting send!\n",
      "@mandrillapp could you add the defaults (if any) to your SMTP header docs? http://help.mandrill.com/entries/21688056-Using-SMTP-Headers-to-customize-your-messages … Thanks!\n",
      "@mandrillapp increases scalability ( http://bit.ly/14myVuH  ) then decreases pricing ( http://bit.ly/13uJA7s  ) #selfinducedcannibalization\n",
      "@mandrillapp There are some issues with your mandrill npm module. What's your preferred way of documenting bugs and issues?\n",
      "@mandrillapp tried refreshing, the link (line 184 on the homepage) goes here http://help.mandrill.com/forums/20689696-smtp-integration …\n",
      "@mandrillapp we cannot even find out the last email sent to, as mandrill page crashes when enquiring\n",
      "@mandrillapp yeap! that's what I meant throttling - throttling before it gets to Mandrill\n",
      "@manojranaweera Looks like bulk increasing volume considerably. Our support team can help with tips to manage warmup: http://help.mandrill.com \n",
      "@marcelosomers @nathansmith FWIW we dumped Postmark in favor of Mandrill. Highly recommended for transactional email.\n",
      "@masuga Use a service like Mandrill not EE mail.\n",
      "@matt_pickett if u want to reach out to other Mailchimp/Mandrill users try: http://awe.sm/r0jHw  http://awe.sm/eEBZ1 \n",
      "@mattwdelong Mind submitting a request at http://help.mandrill.com with your username and workflow so we can investigate?\n",
      "@meeiw @henrik @mnordin håller själv på med en för mandrill. Har ni tittat på: https://github.com/aceofspades/sendgrid_postback …\n",
      "@michaelmior If you're looking to sync unsubscribed addresses with both MailChimp and Mandrill, the best... https://longreply.com/r/1445d273 \n",
      "@nathanbowser Mind submitting a request with details at http://help.mandrill.com ? We're glad to have a look!\n",
      "@nathansmith For production, Mailchimp seems to have a good transactional email system as well: http://mandrill.com/ \n",
      "@reevesman Mandrill is a transactional e-mail service designed to send customized one-to-one e-mails lik... https://longreply.com/r/8c906b44 \n",
      "@reubenpressman @tinyletter you can use @mandrillapp to do that! http://eepurl.com/oDbf5 \n",
      "@richaskew Can you give us some details about where you're seeing that? Submit a request at http://help.mandrill.com \n",
      "@rodbegbie You'd probably have more success with @mandrillapp. I'm not the best postman, I get lost very easily.\n",
      "@rossdeane Mind submitting a request at http://help.mandrill.com with account details if you haven't already? Glad to take a look!\n",
      "@SanjuBhambhani No issues currently. Mind submitting a request at http://help.mandrill.com with account information and details?\n",
      "@Sinue depende de lo que necesites, para simple esta mandrill\n",
      "@Sinue el equivalente de sengrid es mailchip. Mandrill es mas un smtp y tu dices en que url mande la info de las aperturas, click, etc\n",
      "@Tamiyadd If you haven't already, can you submit a request at http://help.mandrill.com  with account details so we can take a look?\n",
      "@thatmarvin We use a custom algorithm for inlining CSS specifically for Mandrill\n",
      "@traskjd they ‘migrate’ everything to Mandrill?\n",
      "@treize2 No general issues. Can you give us more detail of the error(s) you're seeing? Can send more detail via http://help.mandrill.com , too\n",
      "@variuxdavid Possibly, depends on what you're looking to do exactly. Mind submitting a request at http://help.mandrill.com  with more details?\n",
      "@veroapp Any chance you'll be adding Mandrill support to Vero?\n",
      "@wesbos Mandrill is good but I've noticed a lack of attention to detail on @MailChimp's secondary properties (i.e. TinyLetter)\n",
      "#freelance #Jobs Mandrill Template design and strategy implementation by eshuys: Hi there,     I have just had... http://bit.ly/Xy4VJw \n",
      "#HowTo access @mandrillapp by @mailchimp for sending transactional emails with your website http://ow.ly/jJaDg \n",
      "#InternetMarketing Mandrill Template design and strategy implementation by eshuys: Hi there,     I have just h... http://bit.ly/118UsEd \n",
      "#job #freelance Mandrill Template design and strategy implementation by eshuys: Hi there,     I have just had ... http://adf.ly/M0jIC \n",
      "#Job Integrate Mandrill or Send Grid with Ecommerce Store by kate281: We want to push all transactional e... http://bit.ly/11HtHa9  #php\n",
      "#job Mandrill Template design and strategy implementation by eshuys: Hi there,     I have... http://bit.ly/123HNFe  #freelancer #project\n",
      "#Job Mandrill Webhooks Interspire For Bounce Processing Integration by sanu1255: We have a set up of Inte... http://bit.ly/YH6XHT  #php\n",
      "#jobs PHP Developer with Bullhorn API and Mandrill Experience Needed | Elance Job: We have built a job listing... http://bit.ly/Xg24EK \n",
      "#jobs4u #jobs Mandrill Customer-Support Geek http://bit.ly/18d2eND  #ATL #atlanta #GA\n",
      "#Mandrill is cool! Would probably be using this to SMTP based approach for sending transactional emails from now on. \n",
      "#MySql Mandrill Webhooks Interspire For Bounce Processing Integration by sanu1255: We have a set up of Intersp... http://bit.ly/YH7qtF \n",
      "#Newsletters in #WordPress – Use #SendGrid or #Mandrill by @chrislema http://bit.ly/12R8USh  #wp #plugins #plugin\n",
      "#PhotoshopDesign. Mandrill Template design and strategy implementation by eshuys: Hi there,     I have just ha... http://bit.ly/118UsEd \n",
      "#PHP Integrate Mandrill or Send Grid with Ecommerce Store by kate281: We want to push all transactional email ... http://bit.ly/10wBvdy \n",
      "#Templates Mandrill Template design and strategy implementation by eshuys: Hi there,     I have just had ... http://bit.ly/ZTADzB  #Job\n",
      "#wcmelb question: anyone integrated Mandrill with #BuddyPress ?\n",
      "#wcmelb question: how to integrate wp_mail() with MailChimp's Mandrill?\n",
      "After looking at its website, not sure what @MailChimp's Mandrill does, but gosh darn its #logo is nice. #design pic.twitter.com/9OEGuXGJ4T\n",
      "And we're live! Come hear @levelos talk about using MailChimp and Mandrill for newsletters in #Drupal! http://bit.ly/ZAWI4I \n",
      "arrays would seem to be a portion of the solution. but its an area I don't know much about http://jsfiddle.net/mandrill/GAwTw/4/ … #javascript\n",
      "At what point do I give up on @SendGrid and switch over to Mandrill? http://mandrill.com/ \n",
      "Can anyone tell me why this isn't working? http://jsfiddle.net/mandrill/K8EBE/3/ … #javascript #jquery\n",
      "Check out what we've been up to this week, including a pricing change: http://blog.mandrill.com/friday-notes-2013-03-08.html …\n",
      "De l'email transactionnel facile et pas cher avec #Mandrill et #Redhen sous #Drupal : http://bit.ly/Z5e5wa  - Yep.\n",
      "For ppl looking to switch from Sendgrid, there's Mandrill from Mailchimp. Up to 12K emails/mo $0. http://mandrill.com  (cc: @myShoggoth)\n",
      "Found this @mandrillapp knowledge base article on inbound email webhooks useful. Works well. Biased recommendation++. http://help.mandrill.com/entries/22092308-what-is-the-format-of-inbound-email-webhooks …\n",
      "From Coworker about using Mandrill:  \"I would entrust email handling to a Pokemon\".\n",
      "Guys,buat email wordpress,enakan Sendgrid atau Mandrill?\n",
      "Holy shit. It’s here. http://www.mandrill.com/ \n",
      "http://mandrill.com  Estimated Traffic Net Worth $97,943 http://www.Freewebsitereport.org/www.mandrill.com …\n",
      "If any #eecms devs out there develop with MAMP Pro, these are settings you need to send emails via Mandrill. https://www.evernote.com/shard/s9/sh/f6377f27-aa93-48f4-a9dc-4b10adfdf43f/dec196d3e531c3dfff1ceaed8a21452c/res/bc74b49c-e724-4b29-abfb-cb82032732c0/skitch.png …\n",
      "In light of the @sendgrid fiasco it seems like a good day to make an inappropriate sexual joke about the competing service called “ManDrill”\n",
      "Integrate Mandrill or Send Grid with Ecommerce Store by kate281 http://bit.ly/10JzwTc  #freelance\n",
      "Internet-Marketing Mandrill Template design and strategy implementation by eshuys: Hi there,     I have just h... http://bit.ly/ZTBPTB \n",
      "Jo tak to bylo trapny, no:) https://github.com/fabiancz/mandrill-nette/commit/d3eb22c0ca99651a7abfc380d7b47253bbb4832e … Jdu radsi spat. #dev\n",
      "Just a quick PSA:  http://mandrill.com  is awesome if you need email send/receive services for your app.\n",
      "Just love @mandrillapp transactional email service - http://mandrill.com Sorry @SendGrid and @mailjet #timetomoveon\n",
      "Looking for Designer Mandrill Webhooks #Interspire For Bounce Processing Integration by… http://goo.gl/fb/6gXM3 \n",
      "Looking into swapping out @Sendgrid with @Mandrill for Sōsh emails. Anyone done this? Any words of warning?\n",
      "Looking to send #transactional (one-to-one, triggered email from apps)? MailChimp's new product, Mandrill... smtp free\n",
      "Maldito Gmail que fica pedindo login pela web com captcha para email automático de um sistema. Vou testar o Mandrill http://help.mandrill.com/entries/21738467-Using-Mandrill-s-SMTP-integration-with-Web-Frameworks …\n",
      "mandrill (0.0.3): http://is.gd/LTn1aY  Ruby gem for interacting with the Mandrill API.\n",
      "mandrill 1.0.22: A CLI client and Python API library for the Mandrill email as a service platform. http://bit.ly/160NKQ3 \n",
      "mandrill 1.0.29: A CLI client and Python API library for the Mandrill email as a service platform. http://bit.ly/161vNVJ \n",
      "Mandrill API – An alternate to SMTP and SendMail Email Transport: We live in the world where Cloud Computing a... http://bit.ly/12ThlLY\n",
      "Mandrill Template design and strategy implementation by eshuys http://bit.ly/ZTBpwt  #freelance\n",
      "Mandrill Template design and strategy implementation by eshuys: Hi there,     I have just had... http://bit.ly/125h1bH  #freelance #jobs\n",
      "Mandrill Webhooks #Interspire For Bounce Processing Integration by sanu1255… http://goo.gl/fb/XOPpn  #freelance #job\n",
      "Mandrill Webhooks Interspire For Bounce Processing Integration by sanu1255 http://bit.ly/118ybVg  #Job #career #freelance\n",
      "mandrill-api (1.0.19): http://npmjs.org/package/mandrill-api … The official API client for the Mandrill email as a service product.\n",
      "mandrill-api (1.0.25): http://is.gd/wKfRyo  A Ruby API library for the Mandrill email as a service platform.\n",
      "mandrill-rails (0.0.4): http://is.gd/nobiJe  Rails integration for Mandrill\n",
      "Measuring Transactional Email Performance with Mandrill - http://goo.gl/qaGX2\n",
      "Modules Unraveled: 053 Using Mailchimp and Mandrill to Send Newsletters in Drupal with Lev T... http://bit.ly/148Jf4M  via @DrupalPlanet\n",
      "Modules Unraveled: 053 Using Mailchimp and Mandrill to Send Newsletters in Drupal with Lev Tsypin - Mo... http://bit.ly/YO8iuu  #drupal\n",
      "Modules Unraveled: 053 Using Mailchimp and Mandrill to Send Newsletters in Drupal with Lev Tsypin - Modules Un... http://bit.ly/XrAhyS \n",
      "New from @ChrisLema: Newsletters in WordPress  Use SendGrid or Mandrill http://ht.ly/2wtD1T \n",
      "Newsletters in WordPress - Use SendGrid or Mandrill http://goo.gl/KMGdg  via @chrislema\n",
      "Newsletters in WordPress – Use SendGrid or Mandrill: If you're pushing out newsletters in WordPress? Here are ... http://clema.cc/ZET0L3 \n",
      "Nice.. http://www.mandrill.com \n",
      "Ótima ferramenta para envio de e-mails automáticos em sistemas (confirmação, esqueci senha, notificações...): http://mandrill.com \n",
      "Our love affair with transaction emails from CritSend to SendGrid to Mandrill: When we started edocr.co... http://bit.ly/10cOuon  #edocr\n",
      "Our new subscriber profile page: activity timeline, aggregate engagement stats, and Mandrill integratio #BJCBranding http://bit.ly/13waU5c \n",
      "Parse Partners with MailChimp to Bring Power of Mandrill Email API to Parse-Powered Apps http://bit.ly/UNtj4n \n",
      "progress, of a sort :/  http://jsfiddle.net/mandrill/GAwTw/2/ … I'm thinking an array might be needed, was trying to avoid :/ #javascript\n",
      "Psyched that @MailChimp just dropped the prices of Mandrill (their SendGrid  Amazon SES competitor). Ready to rock http://blog.mailchimp.com/unifying-mandrill-and-mailchimp-data/ …\n",
      "Released a couple of updates to Escort this week (some Mandrill and PostageApp fixes). 3rd-party email for #eecms: http://devot-ee.com/add-ons/escort \n",
      "RT @chrislema: Newsletters in #WordPress - Use SendGrid or Mandrill http://goo.gl/ByWBF \n",
      "RT @freedomwalker77: Newsletters in WordPress - Use SendGrid or Mandrill http://goo.gl/ByWBF  via @chrislema\n",
      "Sengrid ó Mandrill ??? suggestions?\n",
      "TAH-DAH! http://jsfiddle.net/mandrill/wLTns/5/ … It now does what I wanted it to at this stage, tomorrow autoplay. #jquery\n",
      "The Mandrill team dishes about building a status page to stand out among a sea of green check marks: http://eepurl.com/xTHgX \n",
      "The wisest mandrill in the jungle. Rafiki! 🌿 @ Disney's Animal Kingdom http://instagram.com/p/X-M_WcxtA7/ \n",
      "This week: move TDP to either DigitalOcean or Linode, switch mail services to Mandrill and provisioning to sunzi.\n",
      "This week's release notes are up! More template options, quota changes and message prioritization: http://blog.mandrill.com/broader-templates-quota-control.html …\n",
      "To Whom It May Concern: @WebPlatform (http://j.mp/10TOHxc ) and @mandrillapp (http://j.mp/10TOHxg ) have the same logo. That is all.\n",
      "Transactional Email Services Review for Application Developers: Mandrill vs. SendGrid http://bit.ly/ZmRCsz \n",
      "Using Nullmailer and Mandrill for Your Ubuntu Server Outboud Mail http://dzone.com/DWQF  #linux\n",
      "ValidationError from mandrill with google app engine's urlfetch http://pyq.io/so/16260022  #python\n",
      "very impressed by the http://mandrill.com/  site - spotless product, marketing & pricing\n",
      "We're unifying MailChimp and Mandrill data. Beware of hummingbirds with tiny cheetah heads. http://bit.ly/1035KIO \n",
      "We've simplified and reduced pricing for everyone. Hooray! http://blog.mandrill.com/new-simpler-pricing.html …\n",
      "We’re Unifying Your Mandrill and MailChimp Data | MailChimp Email Marketing Blog http://bit.ly/Z0iBZM \n",
      "Whaaat, I didn't know @MailChimp had an email delivery api service thingy: @mandrillapp. Neat: http://www.mandrill.com/?utm_source=devcircle&utm_medium=banner&utm_campaign=carbon …\n",
      "would like to send emails for welcome, password resets, payment notifications, etc. what should i use? was looking at mailgun/mandrill\n",
      "Zapier Makes Mandrill Integration Easy | Mandrill Email Platform Blog http://buff.ly/XW8EzX  #lightweight #integration\n",
      "\n",
      "\n",
      "¿En donde esta su remontada Mandrill?\n",
      ".@Katie_PhD Alternate, 'reproachful mandrill' cover of @DavidQuammen's Spillover\n",
      ".@theophani can i get \"drill\" in there? it would be a picture of a mandrill holding a drill. somethin.\n",
      "“@ChrisJBoyland: Baby Mandrill Paignton Zoo 29th April 2013: http://youtu.be/QpjOffyLXGg?a via @YouTube”. This is just so cute!\n",
      "“@MISSMYA #NameAnAmazingBand MANDRILL!” Mint Condition, Maroon 5, The Fray.\n",
      "“Fat City Strut” by Mandrill is my new jam. http://t.thisismyjam.com/siftdigital/_5jl4tyj …\n",
      "【SOUL TRAIN #22】1973年 MANDRILL 中古盤屋でインパクトのあるジャケットを良く見かけたが音を聴いたのはこの番組（95年）が初めて。少しチカーノが入ったファンキーロック・バンド。生演奏が熱い！ http://youtu.be/h9FI_ZoGFAQ \n",
      "@alicegreennn_ but how come you didn't have mandrill\n",
      "@As_TomasRoncero a la mierda el mandrill tocate la polla\n",
      "@Burnziey @sjsharkfinatic I have zach mandrill complaint how direct tv stop showing game\n",
      "@charlie29598 #GreatJob #Mandrill\n",
      "@JustDewYou @isma_longo tu no ables sapo que el mandrill pierde mañana\n",
      "@Khamili_1015 @espsmile t'es vraiment idiot comme si elle comprenais les kr7 idiot , cancre , mandrill , babouin , bico!\n",
      "@mandrill \"The venue should be opening once the 150t of coffee beans has arrived\"\n",
      "@mandrill @CCP_Manifest @CCPGames don't go to Glasgow, it's a horrible dangerous place full of drunken vicious gits, oh wait, eve players...\n",
      "@mandrill @CCPGames I hope they record the whole thing with high quality audio.\n",
      "@mandrill @ccpgames Plus, we have a faint CCP Seagull in the background from the 2nd stream...\n",
      "@mandrill @Freebooted probably try to corner the spice market and become a demigod by fusing with poorly-understood body modifications?\n",
      "@mandrill @Freebooted. I want to say Heinlein but he'd just have a lot of clone orgies #tweetfleet\n",
      "@mandrill @HilmarVeigar ZOMG Want that jacket\n",
      "@mandrill @j_smedley is around here somewhere... He'd know.\n",
      "@mandrill @Kelduum @ReesNoturana @webspaceships @whistlerbean @MaxUrsa Hiding fleets behind moons sounds soo cool ;)\n",
      "@mandrill @kelduum @webspaceships @whistlerbean @maxursa Too bad all these ideas means a fundamentally different game.\n",
      "@mandrill @whistlerbean #eveonline we totally would!\n",
      "@mandrill @Yara_Ash @Freebooted o/ we wish you were here!\n",
      "@mandrill About 5\" long or so.\n",
      "@mandrill Ah seen. No, I meant Britain actually having a summertime lol Temporal shift not good :/\n",
      "@mandrill ahh. I'd have to save for 10 years to go to ff, so imma just save for the CE instead :D\n",
      "@mandrill and this is why I'm here :-)\n",
      "@mandrill Been trying to look up more of these places I read about or hear about but never see\n",
      "@mandrill best thing ever!\n",
      "@mandrill Cheers for the free proofing service - always good to have an extra set of eyes, although the GameSkinny editors are pretty sharp.\n",
      "@mandrill coming soon!\n",
      "@mandrill Do this with ship skins and alliance logos and I will throw my ENTIRE BANK ACCOUNT at CCP. You hear me @CCPGames? #tweetfleet\n",
      "@mandrill HAGGIS VICTOR\n",
      "@mandrill I was just going to tweet you that lol #evefanfest ;)\n",
      "@mandrill I wouldn't be surprised if there are typos though, gonna take a while for my brain to fully recover from Fanfest.\n",
      "@mandrill In EVE, nothing is too far. :)\n",
      "@mandrill n! / ( k! * ( n - k )! ) where n = 5 and k = 4 CORRECTION\n",
      "@mandrill Quite true. I'd kill for frigate / cruiser models.\n",
      "@mandrill resubbed all four accounts, just can't stay away\n",
      "@mandrill Thanks mate, that means a lot - mainly that CCP's evil Fanfest brainwashing technology is as effective as ever. ;)\n",
      "@mandrill u talking abt the CE?\n",
      "@mandrill we have no one with amazing hair to rally around. Fortunately, we picked up a pink hat.\n",
      "@mandrill We'd love to get your feedback! You can send us suggestions here: http://bit.ly/XYe0tL  ^B\n",
      "@mandrill where?.. On twitch ?\n",
      "@mandrill Winamp is still my choice for music. CCCP for video playback.\n",
      "@mandrill Would've included that, but the 140 character limit prevented me. :(\n",
      "@MISSMYA whatchu know about mandrill....wow\n",
      "@Moloko_b @mandrill @CCP_Guard well... At least we have an additional method of diplomacy...\n",
      "@MrChuckD Got a Mandrill t-shirt today, it came with a nice hand-written letter. Shop here, support good people! http://mandrillmusic.com/store-2 \n",
      "@NaattMarcos15 @RaquelTarari quevaaaaa por ser del mandrill no no si te pasaras a otro equipo si jaja LL\n",
      "@namimaaaa mandrillってとこヾ(＠⌒ー⌒＠)ノ おしゃれだし、美容師さんも素敵(((o(*ﾟ▽ﾟ*)o)))\n",
      "@orgullobiri  po entonces para que coño a venido aqui que se hubiese ido al real mandrill castilla y que se hubiese pudrido de asco\n",
      "@Ouhyeah84 ahora has evolucionado a mandrill!!!!\n",
      "@pyrostinger That's a Mandrill!\n",
      "@strangelocation @mandrill @ccp_guard And on that note, gl #CSM8 :p\n",
      "@yrecruit_chris I like sendgrid, but Mandrill is great too.\n",
      "@zptr @Freebooted @mandrill @kirithkodachi Probably need permission, you can't knit a Jayne hat anymore without threat of legal action.\n",
      "#FF Happy Friday to some of our new followers! @Siriasly @jheanley @ThatMattT @JediLaura @psypsoft @PictureChanging @mandrill\n",
      "#NameAnAmazinGBand Mandrill\n",
      "#video:  Outside this Universe The Rainbow Mandrills video Christmas Mos Nicolae Original Song Santa Mandrill http://dlvr.it/3FSdp8 \n",
      "♥ღ ♫♥ Need to Park that Star on your page! ♥Ty! @frankierocker MANDRILL A VERY DIVERSE 70s GROUP W/BROOKLYN ROOT... ♫ http://blip.fm/~1eihrm \n",
      "a latten is a mandrill: gun-shy and numbing\n",
      "a mandrill is a seedtime: crackbrained, not slicker\n",
      "Adicionei como favorito um vídeo @YouTube de @smoothmcgroove http://youtu.be/hyx9-kWYjDI?a  Megaman X - Spark Mandrill Acapella\n",
      "Adicionei como favorito um vídeo @YouTube de @smoothmcgroove http://youtu.be/hyx9-kWYjDI?a  Megaman X - Spark Mandrill Acapella\n",
      "al carajo el mandrill!!!!!!!!!oleoleoleoleoeleoleoeeoleoeleoleole\n",
      "Ala mandrill!!!jajajaja a mamarla hoy vosotrosss!!!\n",
      "Also, don't get into a mandrill fight with Sam Sykes after 2AM. #wordstothewise He will make you google things you regret, forever.\n",
      "An hispanic mandrill gets raucous original save his occupation near high entertainment industry lodge. in back o: .hru\n",
      "And looks like a fat mandrill\n",
      "Anyway, yeah.  That's a thing that's going on.  Reincarnated mandrill-men.  Expect nothing less from Sam Sykes.\n",
      "Arin did the spark mandrill trick I was wondering if he would :')\n",
      "Audio: Mandrill - Happy Beat This is a funk song by a band who liked to wear hats and has a banjo in it. How... http://tmblr.co/Z3ocQyj_JGWB\n",
      "Cannot believe I am the only one in a @mandrill 2012 #tweetfleet t-shirt at the meet!\n",
      "Chill Penguin and Spark Mandrill down. #megamanx\n",
      "Cuando pase el Bafici y se hayan perdido Mandrill, Mirageman, Mujer metralleta y Kiltro a mí no me lloren: http://www.youtube.com/watch?v=x-9CUFDUM_c …\n",
      "De los creadores de #Kiltro #Mirageman y #Mandrill Ahora atacan con #TráiganmeLaCabezaDeLaMujerMetralleta TR http://youtu.be/RHqozwN1ZYI \n",
      "Did this producer sample Mandrill!? I KNOWWWWWWWW you ain't pay for this! BYE SON!\n",
      "Don't knock asshats. Philip Treacy's new line of Mandrill Derrière Fascinators is sublime.\n",
      "Don't know how to name your novel? I say, call it PURPLE MANDRILL COVERED IN FRECKLES: http://www.kseniaanske.com/blog/2013/4/8/naming-your-novel.html …\n",
      "E essa do Mega Man X  (Spark Mandrill) - Muito show! http://fb.me/xquh7u1n \n",
      "Easiest Mega Man boss fights ever: Spark Mandrill, Junk Man, Spring Man, and Cut Man.\n",
      "Esa tambien me gusta mucho *Escuchando Spark Mandrill por Mega Man X #nowplaying #musicmonday  http://grooveshark.com/s/Spark+Mandrill/2NjwQv?src=5 … vía @grooveshark\n",
      "esta cancion sale cuando le disparan a Mandrill en la cabeza ( muere aparentemente ) y salen (@YouTube - http://youtu.be/6B6GwllebrM?a )\n",
      "Fencewalk is STOOPID RT @MISSMYA #NameAnAmazingBand MANDRILL!\n",
      "Fernando Vargas MANDRILL MEXICAN PRIDE MMA\n",
      "Get it get it get it get it goddamn! ♫ Can You Get It (Suzie Caesar) – Mandrill http://spoti.fi/TlEZyp  #Spotify\n",
      "Git It All - Mandrill - Listen Now http://bit.ly/sylJDa\n",
      "Git It All - Mandrill http://rdo.to/KZKO  #nowplaying #listenlive\n",
      "Gooooooolllllll Del Mandrill\n",
      "Gostei de um vídeo @YouTube de @franciscodanrl1 http://youtu.be/Gv98_b1EOIM?a  Megaman X Gameplay Parte #5 Spark Mandrill\n",
      "Gostei de um vídeo @YouTube de @smoothmcgroove http://youtu.be/hyx9-kWYjDI?a  Megaman X - Spark Mandrill Acapella\n",
      "Gostei de um vídeo @YouTube de @smoothmcgroove http://youtu.be/hyx9-kWYjDI?a  Megaman X - Spark Mandrill Acapella\n",
      "Gostei de um vídeo @YouTube de @smoothmcgroove http://youtu.be/hyx9-kWYjDI?a  Megaman X - Spark Mandrill Acapella\n",
      "Gostei de um vídeo @YouTube de @smoothmcgroove http://youtu.be/hyx9-kWYjDI?a  Megaman X - Spark Mandrill Acapella\n",
      "Gostei de um vídeo @YouTube de @smoothmcgroove http://youtu.be/hyx9-kWYjDI?a  Megaman X - Spark Mandrill Acapella\n",
      "Gostei de um vídeo @YouTube de @smoothmcgroove http://youtu.be/hyx9-kWYjDI?a Megaman X - Spark Mandrill Acapella\n",
      "Guess the good mandrill's back! Rafiki is the name. 😁\n",
      "HOY a las 12.35 h No se pierdan MANDRILL de Ernesto Díaz http://j.mp/YkekjO   en el @recoletamall 15 #BAFICI\n",
      "I like pink butts and I cannot lie... Male #mandrill showing off his assets. @ Congo Gorilla Forest http://instagram.com/p/YaUp6vNfH_/ \n",
      "I liked a @YouTube video from @smoothmcgroove http://youtu.be/hyx9-kWYjDI?a  Megaman X - Spark Mandrill Acapella\n",
      "I love the part in Lion King when the mandrill beats the shit out of the hyenas hahahahaha 👊🐒\n",
      "I'm a Mandrill... Of course my inner animal has great hair likes to show off his toosh... #spiritanimal http://bit.ly/wrt54R \n",
      "I'm following @lostbhoy, @mandrill, @Girobabies, @bazzabhoy87, @Linda_Wilsonn and 2 others on @spreaker http://www.spreaker.com/user/joebone \n",
      "ich brauch'n einen chillig gejammten funky mother auf'n freitag abend :3 http://www.youtube.com/watch?v=i6Z_bkj5BBw … mandrill = musikalische götter.\n",
      "Izasata Mandrill-Striker of Eldnoe rolls in to A Whirlpool and is overran by A Big Mind Flayer.\n",
      "Jammin as I get ready to head out in a bit. ♫ Fencewalk – Mandrill http://spoti.fi/O2MhpA  #Spotify\n",
      "Jayne Mandrill & Christopher Bream #animalcelebrities\n",
      "Kaminsky manages toward exasperate an bugging in company with patrovita's reduce to order ruff mandrill rocca he:\n",
      "Le mandrill se casse #instantchiale\n",
      "Mandrill - Aspiration Flame\n",
      "Mandrill - Mango Meat http://www.youtube.com/watch?v=3ohVxEaVQvI …\n",
      "Mandrill Get It All 1973: http://youtu.be/h9FI_ZoGFAQ  via @youtube  funky gift from 1973!\n",
      "Mandrill on Classic Soul Train: http://youtu.be/5qA4g3v1Uwc  via @youtube\n",
      "Meet new PUA artist \"Mandrill.\" He's a monkey\n",
      "Mega Man X's Spark Mandrill Theme, In An Amazing A Capella:  The spectacularly-bearded Smooth McGroove... http://bit.ly/XRoHj8  #kotaku\n",
      "Megaman X - Spark Mandrill Acapella: http://youtu.be/hyx9-kWYjDI  @youtubeさんから\n",
      "Megaman X - Spark Mandrill Acapella: http://youtu.be/hyx9-kWYjDI  THIS IS AMAZING HOLY SHIT\n",
      "Megaman X - Spark Mandrill Acapella: http://youtu.be/hyx9-kWYjDI @youtubeさんから\n",
      "Megaman X - Spark Mandrill Acapella: http://youtu.be/hyx9-kWYjDI @youtubeさんから　この人の選曲わかってる感\n",
      "Megaman X fans, I grace you with an incredible Spark Mandrill a capella. http://www.youtube.com/watch?v=hyx9-kWYjDI …\n",
      "My squad: half-Mandrill, half-Mandela/my band roll 70 deep just like Fela...\n",
      "Nieuw in de verkoop bij Hoekstra&vanEck Mandrill 20, #Wognum €175.000 kosten koper http://bit.ly/17YwI8V \n",
      "One Reason is out! http://paper.li/mandrill/1354033093 … ▸ Top stories today via @Sifteo @BlackMajic_\n",
      "Peter Mandrill Son #animalcelebrities\n",
      "Please help my friend Kumba, the Mandrill, fix his broken leg. http://www.indiegogo.com  search Kumba\n",
      "Que caritas de Gilipollas se le quedaron a los jugadores del Mandrill jajaja\n",
      "Raj shahrukh shogun is an immature mandrill silent endowed with life despite his blood brother which wishes unti: .XzW\n",
      "Silk by Mandrill: http://youtu.be/rtUYx7IF6JM via @youtube\n",
      "Spark mandrill theme #nerdatwork\n",
      "Spark Mandrill, toma Domecq!\n",
      "Stand by Your Mandrill #AnimalSongs\n",
      "Straight a mandrill as looses voluptuous jump at for his pair may discover fabrication problems.:\n",
      "Stukkie stekst geschreven over muziek voor de minderheid en een Public Enemy original http://www.stpaul.nl/2013/04/mandrill-two-sisters-of-mystery/ …\n",
      "Symphonic Revolutions - Mandrill http://rdo.to/WSJR  #nowplaying #listenlive\n",
      "TAQUIPARIU @jurandirfilho olha isso: Mega Man X - Spark Mandrill Theme Acapella - http://www.youtube.com/watch?v=hyx9-kWYjDI …\n",
      "The @TBobbyMitchell 7s cartoon character is live now in RFU online content. Spot him and win big prizes #7shunt #mandrill\n",
      "The #drill & #mandrill were originally classed with #baboons, but have since been put into their own genus, 'Mandrillus'.\n",
      "The two songs in my head went like this: \"Devil in a new dress\" for the first half, \"Can you get it\" by Mandrill for the second half.\n",
      "this little girl is a mandrill. Milwaukee County Zoo, March, 2013. http://twitpic.com/cawbaj \n",
      "Today's music choice: heavy metal cover of Mega Man X's Spark Mandrill theme. What the hell is a Mandrill? http://www.youtube.com/watch?v=XxC0VjiUQAQ …\n",
      "Ushindi the mandrill can't get enough of the snow! Especially when it's covered in fruit + sunflower seeds: http://ow.ly/hYjcq  #FPZoo\n",
      "Vamos atleti !!! Puta mandrill !!!!\n",
      "Why Are Monkey Butts So Colorful?: Mandrill Wikimedia CommonsPlus, the best colored monkey but... http://bit.ly/ZGBN5d  #PopularScience\n",
      "You can now experience the thrills of classic PC gaming with Mandrill Maze. http://mandrillmaze.tumblr.com/  Why? Ehh, I don't know.\n",
      "ジャンルごった煮のバンド、Mandrillの75年作！オススメはOddiseeがサンプリングしたB3「Silk」メロウながらも力強いグルーヴの気持ちイイ1曲です。ジワジワ感が堪りません！Mandrill / Solid http://bit.ly/mTRifR \n",
      "パーカッシヴなビートに重厚なベースやスペイシーなシンセ等が絡むB1が◎な80年の好作！シッカリ打ったドラムながらもメロウなB4などもナイス！Mandrill / Getting In The Mood http://bit.ly/9y5E3f \n",
      "最近ではNottz feat Pete Rock / Turn It Upでも使われていたレア・グルーヴ/ブレイク・クラシック！Mandrill / Mango Meat http://bit.ly/VO4XG8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fox\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "\n",
    "workbook = openpyxl.load_workbook(\"data/mandrill.xlsx\")\n",
    "good = workbook.active\n",
    "\n",
    "for row in range(1, 151):\n",
    "    for col in good.iter_cols(1, good.max_column):\n",
    "        print(col[row].value)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "bad = workbook[\"dot. innych\"]\n",
    "\n",
    "for row in range(1, 151):\n",
    "    for col in bad.iter_cols(1, bad.max_column):\n",
    "        print(col[row].value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[blog] Using Nullmailer and Mandrill for your ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[blog] Using Postfix and free Mandrill email s...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@aalbertson There are several reasons emails g...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@adrienneleigh I just switched it over to Mand...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@ankeshk +1 to @mailchimp We use MailChimp for...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Why Are Monkey Butts So Colorful?: Mandrill Wi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>You can now experience the thrills of classic ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>ジャンルごった煮のバンド、Mandrillの75年作！オススメはOddiseeがサンプリング...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>パーカッシヴなビートに重厚なベースやスペイシーなシンセ等が絡むB1が◎な80年の好作！シッカ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>最近ではNottz feat Pete Rock / Turn It Upでも使われていたレ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              original   good\n",
       "0    [blog] Using Nullmailer and Mandrill for your ...   True\n",
       "1    [blog] Using Postfix and free Mandrill email s...   True\n",
       "2    @aalbertson There are several reasons emails g...   True\n",
       "3    @adrienneleigh I just switched it over to Mand...   True\n",
       "4    @ankeshk +1 to @mailchimp We use MailChimp for...   True\n",
       "..                                                 ...    ...\n",
       "295  Why Are Monkey Butts So Colorful?: Mandrill Wi...  False\n",
       "296  You can now experience the thrills of classic ...  False\n",
       "297  ジャンルごった煮のバンド、Mandrillの75年作！オススメはOddiseeがサンプリング...  False\n",
       "298  パーカッシヴなビートに重厚なベースやスペイシーなシンセ等が絡むB1が◎な80年の好作！シッカ...  False\n",
       "299  最近ではNottz feat Pete Rock / Turn It Upでも使われていたレ...  False\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=[\"original\", \"good\"])\n",
    "\n",
    "for row in range(1, 151):\n",
    "    for col in good.iter_cols(1, good.max_column):\n",
    "        df = pd.concat([df, pd.DataFrame([{\"original\" : col[row].value, \"good\" : True}]) ], ignore_index = True)\n",
    "        \n",
    "for row in range(1, 151):\n",
    "    for col in bad.iter_cols(1, bad.max_column):\n",
    "        df = pd.concat([df, pd.DataFrame([{\"original\" : col[row].value, \"good\" : False}]) ], ignore_index = True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparte the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "import translators as ts\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"data/translated_snapshot.pkl\") == False:\n",
    "    df[\"language\"] = \"\"\n",
    "    df[\"translated\"] = df[\"original\"].copy()\n",
    "    for index, row in df.iterrows():\n",
    "        lang = row[\"original\"]\n",
    "        df[\"language\"][index] = detect(lang)\n",
    "        if df[\"language\"][index] != 'en':\n",
    "            df[\"translated\"][index] = ts.translate_text(row[\"original\"], translator=\"google\")\n",
    "        \n",
    "        print(df[\"translated\"][index])\n",
    "\n",
    "    df.to_pickle(\"data/translated_snapshot.pkl\")\n",
    "else:\n",
    "    df = pd.read_pickle(\"data/translated_snapshot.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>good</th>\n",
       "      <th>language</th>\n",
       "      <th>translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[blog] Using Nullmailer and Mandrill for your ...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>[blog] Using Nullmailer and Mandrill for your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[blog] Using Postfix and free Mandrill email s...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>[blog] Using Postfix and free Mandrill email s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@aalbertson There are several reasons emails g...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>@aalbertson There are several reasons emails g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@adrienneleigh I just switched it over to Mand...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>@adrienneleigh I just switched it over to Mand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@ankeshk +1 to @mailchimp We use MailChimp for...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>@ankeshk +1 to @mailchimp We use MailChimp for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Why Are Monkey Butts So Colorful?: Mandrill Wi...</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>Why Are Monkey Butts So Colorful?: Mandrill Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>You can now experience the thrills of classic ...</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>You can now experience the thrills of classic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>ジャンルごった煮のバンド、Mandrillの75年作！オススメはOddiseeがサンプリング...</td>\n",
       "      <td>False</td>\n",
       "      <td>ja</td>\n",
       "      <td>75 years of Mandrill, a boiled band of genre! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>パーカッシヴなビートに重厚なベースやスペイシーなシンセ等が絡むB1が◎な80年の好作！シッカ...</td>\n",
       "      <td>False</td>\n",
       "      <td>ja</td>\n",
       "      <td>B1 with a heavy bass and Spacey synths on perc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>最近ではNottz feat Pete Rock / Turn It Upでも使われていたレ...</td>\n",
       "      <td>False</td>\n",
       "      <td>ja</td>\n",
       "      <td>Rare Groove / Break Classic, which was also us...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              original   good language  \\\n",
       "0    [blog] Using Nullmailer and Mandrill for your ...   True       en   \n",
       "1    [blog] Using Postfix and free Mandrill email s...   True       en   \n",
       "2    @aalbertson There are several reasons emails g...   True       en   \n",
       "3    @adrienneleigh I just switched it over to Mand...   True       en   \n",
       "4    @ankeshk +1 to @mailchimp We use MailChimp for...   True       en   \n",
       "..                                                 ...    ...      ...   \n",
       "295  Why Are Monkey Butts So Colorful?: Mandrill Wi...  False       en   \n",
       "296  You can now experience the thrills of classic ...  False       en   \n",
       "297  ジャンルごった煮のバンド、Mandrillの75年作！オススメはOddiseeがサンプリング...  False       ja   \n",
       "298  パーカッシヴなビートに重厚なベースやスペイシーなシンセ等が絡むB1が◎な80年の好作！シッカ...  False       ja   \n",
       "299  最近ではNottz feat Pete Rock / Turn It Upでも使われていたレ...  False       ja   \n",
       "\n",
       "                                            translated  \n",
       "0    [blog] Using Nullmailer and Mandrill for your ...  \n",
       "1    [blog] Using Postfix and free Mandrill email s...  \n",
       "2    @aalbertson There are several reasons emails g...  \n",
       "3    @adrienneleigh I just switched it over to Mand...  \n",
       "4    @ankeshk +1 to @mailchimp We use MailChimp for...  \n",
       "..                                                 ...  \n",
       "295  Why Are Monkey Butts So Colorful?: Mandrill Wi...  \n",
       "296  You can now experience the thrills of classic ...  \n",
       "297  75 years of Mandrill, a boiled band of genre! ...  \n",
       "298  B1 with a heavy bass and Spacey synths on perc...  \n",
       "299  Rare Groove / Break Classic, which was also us...  \n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Has URL / Has mandrill URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has mandrill url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\27535148.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has url\"][index] = True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>good</th>\n",
       "      <th>language</th>\n",
       "      <th>translated</th>\n",
       "      <th>has url</th>\n",
       "      <th>has mandrill url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[blog] Using Nullmailer and Mandrill for your ...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>[blog] Using Nullmailer and Mandrill for your ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[blog] Using Postfix and free Mandrill email s...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>[blog] Using Postfix and free Mandrill email s...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@aalbertson There are several reasons emails g...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>@aalbertson There are several reasons emails g...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@adrienneleigh I just switched it over to Mand...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>@adrienneleigh I just switched it over to Mand...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@ankeshk +1 to @mailchimp We use MailChimp for...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>@ankeshk +1 to @mailchimp We use MailChimp for...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Why Are Monkey Butts So Colorful?: Mandrill Wi...</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>Why Are Monkey Butts So Colorful?: Mandrill Wi...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>You can now experience the thrills of classic ...</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>You can now experience the thrills of classic ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>ジャンルごった煮のバンド、Mandrillの75年作！オススメはOddiseeがサンプリング...</td>\n",
       "      <td>False</td>\n",
       "      <td>ja</td>\n",
       "      <td>75 years of Mandrill, a boiled band of genre! ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>パーカッシヴなビートに重厚なベースやスペイシーなシンセ等が絡むB1が◎な80年の好作！シッカ...</td>\n",
       "      <td>False</td>\n",
       "      <td>ja</td>\n",
       "      <td>B1 with a heavy bass and Spacey synths on perc...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>最近ではNottz feat Pete Rock / Turn It Upでも使われていたレ...</td>\n",
       "      <td>False</td>\n",
       "      <td>ja</td>\n",
       "      <td>Rare Groove / Break Classic, which was also us...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              original   good language  \\\n",
       "0    [blog] Using Nullmailer and Mandrill for your ...   True       en   \n",
       "1    [blog] Using Postfix and free Mandrill email s...   True       en   \n",
       "2    @aalbertson There are several reasons emails g...   True       en   \n",
       "3    @adrienneleigh I just switched it over to Mand...   True       en   \n",
       "4    @ankeshk +1 to @mailchimp We use MailChimp for...   True       en   \n",
       "..                                                 ...    ...      ...   \n",
       "295  Why Are Monkey Butts So Colorful?: Mandrill Wi...  False       en   \n",
       "296  You can now experience the thrills of classic ...  False       en   \n",
       "297  ジャンルごった煮のバンド、Mandrillの75年作！オススメはOddiseeがサンプリング...  False       ja   \n",
       "298  パーカッシヴなビートに重厚なベースやスペイシーなシンセ等が絡むB1が◎な80年の好作！シッカ...  False       ja   \n",
       "299  最近ではNottz feat Pete Rock / Turn It Upでも使われていたレ...  False       ja   \n",
       "\n",
       "                                            translated  has url  \\\n",
       "0    [blog] Using Nullmailer and Mandrill for your ...     True   \n",
       "1    [blog] Using Postfix and free Mandrill email s...     True   \n",
       "2    @aalbertson There are several reasons emails g...     True   \n",
       "3    @adrienneleigh I just switched it over to Mand...    False   \n",
       "4    @ankeshk +1 to @mailchimp We use MailChimp for...    False   \n",
       "..                                                 ...      ...   \n",
       "295  Why Are Monkey Butts So Colorful?: Mandrill Wi...     True   \n",
       "296  You can now experience the thrills of classic ...     True   \n",
       "297  75 years of Mandrill, a boiled band of genre! ...     True   \n",
       "298  B1 with a heavy bass and Spacey synths on perc...     True   \n",
       "299  Rare Groove / Break Classic, which was also us...     True   \n",
       "\n",
       "     has mandrill url  \n",
       "0               False  \n",
       "1               False  \n",
       "2                True  \n",
       "3               False  \n",
       "4               False  \n",
       "..                ...  \n",
       "295             False  \n",
       "296             False  \n",
       "297             False  \n",
       "298             False  \n",
       "299             False  \n",
       "\n",
       "[300 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "df[\"has url\"] = False\n",
    "df[\"has mandrill url\"] = False\n",
    "\n",
    "f = re.search(r'http[s]*:\\/\\/(?:[a-z0-9_\\-]+[.])*(?:mandrill.com)(?:\\/[a-zA-Z\\-\\/0-9]+)*', \n",
    "              r'@mandrillapp could you add the defaults (if any) to your SMTP header docs? http://help.mandrill.com/entries/21688056-Using-SMTP-Headers-to-customize-your-messages … Thanks!')\n",
    "\n",
    "if f == None:\n",
    "    raise \"Bad regex\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    og = row[\"original\"]\n",
    "    f = re.search(r'http[s]*:\\/\\/(?:[a-z0-9_\\-]+[.])*(?:mandrill.com)(?:\\/[a-zA-Z\\-\\/0-9]+)*', og, flags=re.IGNORECASE)\n",
    "    url_f = re.search(r'http[s]*:\\/\\/', og, flags=re.IGNORECASE)\n",
    "    if(f != None):\n",
    "        df[\"has mandrill url\"][index] = True\n",
    "    if(url_f != None):\n",
    "        df[\"has url\"][index] = True\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore most common @s (at me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@mandrill', 43),\n",
       " ('@youtube', 15),\n",
       " ('@mandrillapp', 14),\n",
       " ('@smoothmcgroove', 9),\n",
       " ('@mailchimp', 6),\n",
       " ('@camj59', 5),\n",
       " ('@chrislema', 5),\n",
       " ('@sendgrid', 4),\n",
       " ('@ccpgames', 4),\n",
       " ('@freebooted', 4),\n",
       " ('@devongovett', 3),\n",
       " ('@eladlouni', 3),\n",
       " ('@sinue', 3),\n",
       " ('@missmya', 3),\n",
       " ('@whistlerbean', 3),\n",
       " ('@dzuelke', 2),\n",
       " ('@elie__', 2),\n",
       " ('@nathansmith', 2),\n",
       " ('@kelduum', 2),\n",
       " ('@webspaceships', 2),\n",
       " ('@maxursa', 2),\n",
       " ('@ccp_guard', 2),\n",
       " ('@aalbertson', 1),\n",
       " ('@adrienneleigh', 1),\n",
       " ('@ankeshk', 1),\n",
       " ('@sampad', 1),\n",
       " ('@abhijeetmk', 1),\n",
       " ('@hiway', 1),\n",
       " ('@biggoldring', 1),\n",
       " ('@bluehayes', 1),\n",
       " ('@cemsisman', 1),\n",
       " ('@compactcode', 1),\n",
       " ('@edocr', 1),\n",
       " ('@ericcandino', 1),\n",
       " ('@flo_rian', 1),\n",
       " ('@frankioh', 1),\n",
       " ('@gidogeek', 1),\n",
       " ('@guillaumepotier', 1),\n",
       " ('@icntmx', 1),\n",
       " ('@jeremyweir', 1),\n",
       " ('@josscrowcroft', 1),\n",
       " ('@juanpabloaj', 1),\n",
       " ('@kanonbulle', 1),\n",
       " ('@kennydude', 1),\n",
       " ('@kennyfraser', 1),\n",
       " ('@khiger', 1),\n",
       " ('@ljharb', 1),\n",
       " ('@manojranaweera', 1),\n",
       " ('@marcelosomers', 1),\n",
       " ('@masuga', 1),\n",
       " ('@matt_pickett', 1),\n",
       " ('@mattwdelong', 1),\n",
       " ('@meeiw', 1),\n",
       " ('@henrik', 1),\n",
       " ('@mnordin', 1),\n",
       " ('@michaelmior', 1),\n",
       " ('@nathanbowser', 1),\n",
       " ('@reevesman', 1),\n",
       " ('@reubenpressman', 1),\n",
       " ('@tinyletter', 1),\n",
       " ('@richaskew', 1),\n",
       " ('@rodbegbie', 1),\n",
       " ('@rossdeane', 1),\n",
       " ('@sanjubhambhani', 1),\n",
       " ('@tamiyadd', 1),\n",
       " ('@thatmarvin', 1),\n",
       " ('@traskjd', 1),\n",
       " ('@treize2', 1),\n",
       " ('@variuxdavid', 1),\n",
       " ('@veroapp', 1),\n",
       " ('@wesbos', 1),\n",
       " ('@levelos', 1),\n",
       " ('@myshoggoth', 1),\n",
       " ('@mailjet', 1),\n",
       " ('@drupalplanet', 1),\n",
       " ('@freedomwalker77', 1),\n",
       " ('@webplatform', 1),\n",
       " ('@katie_phd', 1),\n",
       " ('@davidquammen', 1),\n",
       " ('@theophani', 1),\n",
       " ('@chrisjboyland', 1),\n",
       " ('@alicegreennn_', 1),\n",
       " ('@as_tomasroncero', 1),\n",
       " ('@burnziey', 1),\n",
       " ('@sjsharkfinatic', 1),\n",
       " ('@charlie29598', 1),\n",
       " ('@justdewyou', 1),\n",
       " ('@isma_longo', 1),\n",
       " ('@khamili_1015', 1),\n",
       " ('@espsmile', 1),\n",
       " ('@ccp_manifest', 1),\n",
       " ('@hilmarveigar', 1),\n",
       " ('@j_smedley', 1),\n",
       " ('@reesnoturana', 1),\n",
       " ('@yara_ash', 1),\n",
       " ('@moloko_b', 1),\n",
       " ('@mrchuckd', 1),\n",
       " ('@naattmarcos15', 1),\n",
       " ('@raqueltarari', 1),\n",
       " ('@namimaaaa', 1),\n",
       " ('@orgullobiri', 1),\n",
       " ('@ouhyeah84', 1),\n",
       " ('@pyrostinger', 1),\n",
       " ('@strangelocation', 1),\n",
       " ('@yrecruit_chris', 1),\n",
       " ('@zptr', 1),\n",
       " ('@kirithkodachi', 1),\n",
       " ('@siriasly', 1),\n",
       " ('@jheanley', 1),\n",
       " ('@thatmattt', 1),\n",
       " ('@jedilaura', 1),\n",
       " ('@psypsoft', 1),\n",
       " ('@picturechanging', 1),\n",
       " ('@frankierocker', 1),\n",
       " ('@grooveshark', 1),\n",
       " ('@franciscodanrl1', 1),\n",
       " ('@recoletamall', 1),\n",
       " ('@lostbhoy', 1),\n",
       " ('@girobabies', 1),\n",
       " ('@bazzabhoy87', 1),\n",
       " ('@linda_wilsonn', 1),\n",
       " ('@spreaker', 1),\n",
       " ('@sifteo', 1),\n",
       " ('@blackmajic_', 1),\n",
       " ('@jurandirfilho', 1),\n",
       " ('@tbobbymitchell', 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ats = {}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    og = row[\"original\"]\n",
    "    fl = re.findall(r'(?:@[a-zA-Z0-9_]+\\b)', og, flags=re.IGNORECASE)\n",
    "\n",
    "    if len(fl) != 0:\n",
    "        for f in fl:\n",
    "            lower = f.lower()\n",
    "            if lower in ats:\n",
    "                ats[lower] = ats[lower] + 1\n",
    "            else:\n",
    "                ats[lower] = 1\n",
    "\n",
    "ats = list(ats.items())\n",
    "ats.sort(key = lambda x : x[1], reverse=True)\n",
    "ats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect the most popular tags that don't belong to private people:\n",
    "@mandrill\n",
    "@youtube\n",
    "@mandrillapp\n",
    "@smoothmcgroove\n",
    "@mailchimp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Has tag @mandrill @youtube @mandrillapp @smoothmcgroove @mailchimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>good</th>\n",
       "      <th>language</th>\n",
       "      <th>translated</th>\n",
       "      <th>has url</th>\n",
       "      <th>has mandrill url</th>\n",
       "      <th>has @mandrill</th>\n",
       "      <th>has @youtube</th>\n",
       "      <th>has @mandrillapp</th>\n",
       "      <th>has @smoothmcgroove</th>\n",
       "      <th>has @mailchimp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[blog] Using Nullmailer and Mandrill for your ...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>[blog] Using Nullmailer and Mandrill for your ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[blog] Using Postfix and free Mandrill email s...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>[blog] Using Postfix and free Mandrill email s...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@aalbertson There are several reasons emails g...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>@aalbertson There are several reasons emails g...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@adrienneleigh I just switched it over to Mand...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>@adrienneleigh I just switched it over to Mand...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@ankeshk +1 to @mailchimp We use MailChimp for...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>@ankeshk +1 to @mailchimp We use MailChimp for...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Why Are Monkey Butts So Colorful?: Mandrill Wi...</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>Why Are Monkey Butts So Colorful?: Mandrill Wi...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>You can now experience the thrills of classic ...</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>You can now experience the thrills of classic ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>ジャンルごった煮のバンド、Mandrillの75年作！オススメはOddiseeがサンプリング...</td>\n",
       "      <td>False</td>\n",
       "      <td>ja</td>\n",
       "      <td>75 years of Mandrill, a boiled band of genre! ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>パーカッシヴなビートに重厚なベースやスペイシーなシンセ等が絡むB1が◎な80年の好作！シッカ...</td>\n",
       "      <td>False</td>\n",
       "      <td>ja</td>\n",
       "      <td>B1 with a heavy bass and Spacey synths on perc...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>最近ではNottz feat Pete Rock / Turn It Upでも使われていたレ...</td>\n",
       "      <td>False</td>\n",
       "      <td>ja</td>\n",
       "      <td>Rare Groove / Break Classic, which was also us...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              original   good language  \\\n",
       "0    [blog] Using Nullmailer and Mandrill for your ...   True       en   \n",
       "1    [blog] Using Postfix and free Mandrill email s...   True       en   \n",
       "2    @aalbertson There are several reasons emails g...   True       en   \n",
       "3    @adrienneleigh I just switched it over to Mand...   True       en   \n",
       "4    @ankeshk +1 to @mailchimp We use MailChimp for...   True       en   \n",
       "..                                                 ...    ...      ...   \n",
       "295  Why Are Monkey Butts So Colorful?: Mandrill Wi...  False       en   \n",
       "296  You can now experience the thrills of classic ...  False       en   \n",
       "297  ジャンルごった煮のバンド、Mandrillの75年作！オススメはOddiseeがサンプリング...  False       ja   \n",
       "298  パーカッシヴなビートに重厚なベースやスペイシーなシンセ等が絡むB1が◎な80年の好作！シッカ...  False       ja   \n",
       "299  最近ではNottz feat Pete Rock / Turn It Upでも使われていたレ...  False       ja   \n",
       "\n",
       "                                            translated  has url  \\\n",
       "0    [blog] Using Nullmailer and Mandrill for your ...     True   \n",
       "1    [blog] Using Postfix and free Mandrill email s...     True   \n",
       "2    @aalbertson There are several reasons emails g...     True   \n",
       "3    @adrienneleigh I just switched it over to Mand...    False   \n",
       "4    @ankeshk +1 to @mailchimp We use MailChimp for...    False   \n",
       "..                                                 ...      ...   \n",
       "295  Why Are Monkey Butts So Colorful?: Mandrill Wi...     True   \n",
       "296  You can now experience the thrills of classic ...     True   \n",
       "297  75 years of Mandrill, a boiled band of genre! ...     True   \n",
       "298  B1 with a heavy bass and Spacey synths on perc...     True   \n",
       "299  Rare Groove / Break Classic, which was also us...     True   \n",
       "\n",
       "     has mandrill url  has @mandrill  has @youtube  has @mandrillapp  \\\n",
       "0               False          False         False             False   \n",
       "1               False          False         False             False   \n",
       "2                True          False         False             False   \n",
       "3               False          False         False             False   \n",
       "4               False          False         False             False   \n",
       "..                ...            ...           ...               ...   \n",
       "295             False          False         False             False   \n",
       "296             False          False         False             False   \n",
       "297             False          False         False             False   \n",
       "298             False          False         False             False   \n",
       "299             False          False         False             False   \n",
       "\n",
       "     has @smoothmcgroove  has @mailchimp  \n",
       "0                  False           False  \n",
       "1                  False           False  \n",
       "2                  False           False  \n",
       "3                  False           False  \n",
       "4                  False            True  \n",
       "..                   ...             ...  \n",
       "295                False           False  \n",
       "296                False           False  \n",
       "297                False           False  \n",
       "298                False           False  \n",
       "299                False           False  \n",
       "\n",
       "[300 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def has_tag(tag, row):\n",
    "    og = row[\"original\"]\n",
    "    f = re.search(f'(?:@{tag}\\\\b)', og, flags=re.IGNORECASE)\n",
    "    return f != None\n",
    "\n",
    "for tag in [\"mandrill\", \"youtube\", \"mandrillapp\", \"smoothmcgroove\", \"mailchimp\"]:\n",
    "    df[f\"has @{tag}\"] = df.apply(lambda row : has_tag(tag, row), axis = 1)\n",
    "\n",
    "df.to_csv(path_or_buf=\"data/test.csv\", sep=';')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore most common #tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#mandrill', 8),\n",
       " ('#freelance', 7),\n",
       " ('#job', 7),\n",
       " ('#jobs', 4),\n",
       " ('#php', 3),\n",
       " ('#drupal', 3),\n",
       " ('#javascript', 3),\n",
       " ('#nameanamazingband', 3),\n",
       " ('#tweetfleet', 3),\n",
       " ('#nowplaying', 3),\n",
       " ('#plone', 2),\n",
       " ('#wordpress', 2),\n",
       " ('#wcmelb', 2),\n",
       " ('#jquery', 2),\n",
       " ('#eecms', 2),\n",
       " ('#interspire', 2),\n",
       " ('#spotify', 2),\n",
       " ('#listenlive', 2),\n",
       " ('#animalcelebrities', 2),\n",
       " ('#enginehosting', 1),\n",
       " ('#selfinducedcannibalization', 1),\n",
       " ('#howto', 1),\n",
       " ('#internetmarketing', 1),\n",
       " ('#freelancer', 1),\n",
       " ('#project', 1),\n",
       " ('#jobs4u', 1),\n",
       " ('#atl', 1),\n",
       " ('#atlanta', 1),\n",
       " ('#ga', 1),\n",
       " ('#mysql', 1),\n",
       " ('#newsletters', 1),\n",
       " ('#sendgrid', 1),\n",
       " ('#wp', 1),\n",
       " ('#plugins', 1),\n",
       " ('#plugin', 1),\n",
       " ('#photoshopdesign', 1),\n",
       " ('#templates', 1),\n",
       " ('#buddypress', 1),\n",
       " ('#logo', 1),\n",
       " ('#design', 1),\n",
       " ('#redhen', 1),\n",
       " ('#dev', 1),\n",
       " ('#timetomoveon', 1),\n",
       " ('#transactional', 1),\n",
       " ('#career', 1),\n",
       " ('#edocr', 1),\n",
       " ('#bjcbranding', 1),\n",
       " ('#linux', 1),\n",
       " ('#python', 1),\n",
       " ('#lightweight', 1),\n",
       " ('#integration', 1),\n",
       " ('#22', 1),\n",
       " ('#greatjob', 1),\n",
       " ('#eveonline', 1),\n",
       " ('#evefanfest', 1),\n",
       " ('#csm8', 1),\n",
       " ('#ff', 1),\n",
       " ('#video', 1),\n",
       " ('#wordstothewise', 1),\n",
       " ('#megamanx', 1),\n",
       " ('#kiltro', 1),\n",
       " ('#mirageman', 1),\n",
       " ('#musicmonday', 1),\n",
       " ('#5', 1),\n",
       " ('#bafici', 1),\n",
       " ('#spiritanimal', 1),\n",
       " ('#instantchiale', 1),\n",
       " ('#kotaku', 1),\n",
       " ('#wognum', 1),\n",
       " ('#nerdatwork', 1),\n",
       " ('#animalsongs', 1),\n",
       " ('#7shunt', 1),\n",
       " ('#drill', 1),\n",
       " ('#baboons', 1),\n",
       " ('#fpzoo', 1),\n",
       " ('#popularscience', 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ats = {}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    og = row[\"original\"]\n",
    "    fl = re.findall(r'(?:#[a-zA-Z0-9_\\-]+\\b)', og, flags=re.IGNORECASE)\n",
    "\n",
    "    if len(fl) != 0:\n",
    "        for f in fl:\n",
    "            lower = f.lower()\n",
    "            if lower in ats:\n",
    "                ats[lower] = ats[lower] + 1\n",
    "            else:\n",
    "                ats[lower] = 1\n",
    "\n",
    "ats = list(ats.items())\n",
    "ats.sort(key = lambda x : x[1], reverse=True)\n",
    "ats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the most interesting #tags\n",
    "#mandrill\n",
    "#freelance\n",
    "#job\n",
    "#jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Has #mandrill #freelance #job #jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>good</th>\n",
       "      <th>language</th>\n",
       "      <th>translated</th>\n",
       "      <th>has url</th>\n",
       "      <th>has mandrill url</th>\n",
       "      <th>has @mandrill</th>\n",
       "      <th>has @youtube</th>\n",
       "      <th>has @mandrillapp</th>\n",
       "      <th>has @smoothmcgroove</th>\n",
       "      <th>has @mailchimp</th>\n",
       "      <th>has #mandrill</th>\n",
       "      <th>has #freelance</th>\n",
       "      <th>has #job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[blog] Using Nullmailer and Mandrill for your ...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>[blog] Using Nullmailer and Mandrill for your ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[blog] Using Postfix and free Mandrill email s...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>[blog] Using Postfix and free Mandrill email s...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@aalbertson There are several reasons emails g...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>@aalbertson There are several reasons emails g...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@adrienneleigh I just switched it over to Mand...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>@adrienneleigh I just switched it over to Mand...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@ankeshk +1 to @mailchimp We use MailChimp for...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>@ankeshk +1 to @mailchimp We use MailChimp for...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Why Are Monkey Butts So Colorful?: Mandrill Wi...</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>Why Are Monkey Butts So Colorful?: Mandrill Wi...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>You can now experience the thrills of classic ...</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>You can now experience the thrills of classic ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>ジャンルごった煮のバンド、Mandrillの75年作！オススメはOddiseeがサンプリング...</td>\n",
       "      <td>False</td>\n",
       "      <td>ja</td>\n",
       "      <td>75 years of Mandrill, a boiled band of genre! ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>パーカッシヴなビートに重厚なベースやスペイシーなシンセ等が絡むB1が◎な80年の好作！シッカ...</td>\n",
       "      <td>False</td>\n",
       "      <td>ja</td>\n",
       "      <td>B1 with a heavy bass and Spacey synths on perc...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>最近ではNottz feat Pete Rock / Turn It Upでも使われていたレ...</td>\n",
       "      <td>False</td>\n",
       "      <td>ja</td>\n",
       "      <td>Rare Groove / Break Classic, which was also us...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              original   good language  \\\n",
       "0    [blog] Using Nullmailer and Mandrill for your ...   True       en   \n",
       "1    [blog] Using Postfix and free Mandrill email s...   True       en   \n",
       "2    @aalbertson There are several reasons emails g...   True       en   \n",
       "3    @adrienneleigh I just switched it over to Mand...   True       en   \n",
       "4    @ankeshk +1 to @mailchimp We use MailChimp for...   True       en   \n",
       "..                                                 ...    ...      ...   \n",
       "295  Why Are Monkey Butts So Colorful?: Mandrill Wi...  False       en   \n",
       "296  You can now experience the thrills of classic ...  False       en   \n",
       "297  ジャンルごった煮のバンド、Mandrillの75年作！オススメはOddiseeがサンプリング...  False       ja   \n",
       "298  パーカッシヴなビートに重厚なベースやスペイシーなシンセ等が絡むB1が◎な80年の好作！シッカ...  False       ja   \n",
       "299  最近ではNottz feat Pete Rock / Turn It Upでも使われていたレ...  False       ja   \n",
       "\n",
       "                                            translated  has url  \\\n",
       "0    [blog] Using Nullmailer and Mandrill for your ...     True   \n",
       "1    [blog] Using Postfix and free Mandrill email s...     True   \n",
       "2    @aalbertson There are several reasons emails g...     True   \n",
       "3    @adrienneleigh I just switched it over to Mand...    False   \n",
       "4    @ankeshk +1 to @mailchimp We use MailChimp for...    False   \n",
       "..                                                 ...      ...   \n",
       "295  Why Are Monkey Butts So Colorful?: Mandrill Wi...     True   \n",
       "296  You can now experience the thrills of classic ...     True   \n",
       "297  75 years of Mandrill, a boiled band of genre! ...     True   \n",
       "298  B1 with a heavy bass and Spacey synths on perc...     True   \n",
       "299  Rare Groove / Break Classic, which was also us...     True   \n",
       "\n",
       "     has mandrill url  has @mandrill  has @youtube  has @mandrillapp  \\\n",
       "0               False          False         False             False   \n",
       "1               False          False         False             False   \n",
       "2                True          False         False             False   \n",
       "3               False          False         False             False   \n",
       "4               False          False         False             False   \n",
       "..                ...            ...           ...               ...   \n",
       "295             False          False         False             False   \n",
       "296             False          False         False             False   \n",
       "297             False          False         False             False   \n",
       "298             False          False         False             False   \n",
       "299             False          False         False             False   \n",
       "\n",
       "     has @smoothmcgroove  has @mailchimp  has #mandrill  has #freelance  \\\n",
       "0                  False           False          False           False   \n",
       "1                  False           False          False           False   \n",
       "2                  False           False          False           False   \n",
       "3                  False           False          False           False   \n",
       "4                  False            True          False           False   \n",
       "..                   ...             ...            ...             ...   \n",
       "295                False           False          False           False   \n",
       "296                False           False          False           False   \n",
       "297                False           False          False           False   \n",
       "298                False           False          False           False   \n",
       "299                False           False          False           False   \n",
       "\n",
       "     has #job  \n",
       "0       False  \n",
       "1       False  \n",
       "2       False  \n",
       "3       False  \n",
       "4       False  \n",
       "..        ...  \n",
       "295     False  \n",
       "296     False  \n",
       "297     False  \n",
       "298     False  \n",
       "299     False  \n",
       "\n",
       "[300 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def has_tag(tag, row):\n",
    "    og = row[\"original\"]\n",
    "    f = re.search(f'(?:#{tag}\\\\b)', og, flags=re.IGNORECASE)\n",
    "    return f != None\n",
    "\n",
    "for tag in [\"mandrill\", \"freelance\"]:\n",
    "    df[f\"has #{tag}\"] = df.apply(lambda row : has_tag(tag, row), axis = 1)\n",
    "\n",
    "def has_job(row):\n",
    "    og = row[\"original\"]\n",
    "    f = re.search(f'(?:#job[s]*\\\\b)', og, flags=re.IGNORECASE)\n",
    "    return f != None\n",
    "\n",
    "df[f\"has #job\"] = df.apply(lambda row : has_job(row), axis = 1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [blog, nullmailer, mandrill, ubuntu, linux, se...\n",
       "1      [blog, postfix, free, mandrill, email, service...\n",
       "2      [reason, email, spam, mind, submitting, reques...\n",
       "3      [switched, mandrill, let, improve, speed, emai...\n",
       "4      [use, mailchimp, marketing, email, mandrill, a...\n",
       "                             ...                        \n",
       "295    [monkey, butt, colorful, mandrill, wikimedia, ...\n",
       "296    [experience, thrill, classic, pc, gaming, mand...\n",
       "297    [year, mandrill, boiled, band, genre, recommen...\n",
       "298    [heavy, bas, spacey, synth, percussive, beat, ...\n",
       "299    [rare, groove, break, classic, nottz, feat, pe...\n",
       "Name: split, Length: 300, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import inflect\n",
    "p = inflect.engine()\n",
    "\n",
    "en = spacy.load(\"en_core_web_lg\")\n",
    "stop_list = en.Defaults.stop_words\n",
    "\n",
    "def split_translated(row):\n",
    "    translated = row[\"translated\"]\n",
    "    split = translated.split()\n",
    "\n",
    "    # To lower case\n",
    "    split = list(map(lambda s : s.lower(), split))\n",
    "\n",
    "    # Remove urls\n",
    "    split = [s for s in split if re.search(r'http[s]*:\\/\\/', s, flags=re.IGNORECASE) == None]\n",
    "\n",
    "    # Remove tags\n",
    "    split = [s for s in split if not ('#' in s)]\n",
    "\n",
    "    # Remove @\n",
    "    split = [s for s in split if not ('@' in s)]\n",
    "\n",
    "    # Remove everything that contains digits\n",
    "    split = [s for s in split if not re.search(r'[0-9]', s) != None]\n",
    "\n",
    "    # Remove non-alphanumeric bs\n",
    "    split = list(map(lambda s : ''.join(ch for ch in s if ch.isalpha()), split))\n",
    "\n",
    "    # Remove spaces\n",
    "    split = list(map(lambda s : s.strip(), split))\n",
    "\n",
    "    # Remove stop-list\n",
    "    split = [s for s in split if not s in stop_list]\n",
    "\n",
    "    # Remove empty\n",
    "    split = [s for s in split if len(s) != 0]\n",
    "\n",
    "    def to_singular(s):\n",
    "        singular = p.singular_noun(s)\n",
    "        if singular == False:\n",
    "            return s\n",
    "        return singular\n",
    "\n",
    "    split = list(map(to_singular, split))\n",
    "\n",
    "    return split\n",
    "\n",
    "df[f\"split\"] = df.apply(lambda row : split_translated(row), axis = 1)\n",
    "df[\"split\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count number of occurences of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('blog', 4),\n",
       " ('nullmailer', 2),\n",
       " ('mandrill', 187),\n",
       " ('ubuntu', 3),\n",
       " ('linux', 2),\n",
       " ('server', 3),\n",
       " ('outboud', 2),\n",
       " ('mail', 4),\n",
       " ('postfix', 1),\n",
       " ('free', 3),\n",
       " ('email', 44),\n",
       " ('service', 16),\n",
       " ('smtp', 7),\n",
       " ('reason', 4),\n",
       " ('spam', 2),\n",
       " ('mind', 12),\n",
       " ('submitting', 10),\n",
       " ('request', 16),\n",
       " ('additional', 4),\n",
       " ('detail', 18),\n",
       " ('switched', 1),\n",
       " ('let', 3),\n",
       " ('improve', 1),\n",
       " ('speed', 1),\n",
       " ('sent', 2),\n",
       " ('use', 11),\n",
       " ('mailchimp', 19),\n",
       " ('marketing', 3),\n",
       " ('app', 5),\n",
       " ('txn', 1),\n",
       " ('error', 2),\n",
       " ('occur', 1),\n",
       " ('unsupported', 1),\n",
       " ('auth', 1),\n",
       " ('method', 2),\n",
       " ('sending', 6),\n",
       " ('account', 10),\n",
       " ('thing', 5),\n",
       " ('look', 9),\n",
       " ('correct', 1),\n",
       " ('need', 7),\n",
       " ('vary', 1),\n",
       " ('low', 1),\n",
       " ('volume', 2),\n",
       " ('worth', 3),\n",
       " ('offer', 1),\n",
       " ('submit', 6),\n",
       " ('checked', 1),\n",
       " ('transactional', 13),\n",
       " ('run', 1),\n",
       " ('im', 7),\n",
       " ('saving', 1),\n",
       " ('issue', 8),\n",
       " ('domain', 2),\n",
       " ('getting', 1),\n",
       " ('blocked', 1),\n",
       " ('bounce', 6),\n",
       " ('message', 2),\n",
       " ('hard', 1),\n",
       " ('debug', 1),\n",
       " ('pretty', 2),\n",
       " ('cheap', 2),\n",
       " ('option', 2),\n",
       " ('set', 4),\n",
       " ('integration', 8),\n",
       " ('available', 1),\n",
       " ('owner', 1),\n",
       " ('ar', 1),\n",
       " ('able', 1),\n",
       " ('login', 2),\n",
       " ('directly', 1),\n",
       " ('username', 2),\n",
       " ('pa', 1),\n",
       " ('send', 15),\n",
       " ('page', 5),\n",
       " ('crashing', 1),\n",
       " ('youre', 7),\n",
       " ('seeing', 4),\n",
       " ('ye', 1),\n",
       " ('cheaper', 1),\n",
       " ('ditto', 1),\n",
       " ('allow', 1),\n",
       " ('manage', 3),\n",
       " ('contact', 1),\n",
       " ('list', 2),\n",
       " ('example', 3),\n",
       " ('want', 8),\n",
       " ('cannibalize', 1),\n",
       " ('management', 1),\n",
       " ('dont', 7),\n",
       " ('kill', 2),\n",
       " ('time', 2),\n",
       " ('expensive', 1),\n",
       " ('cc', 2),\n",
       " ('jparle', 1),\n",
       " ('de', 4),\n",
       " ('relai', 1),\n",
       " ('million', 2),\n",
       " ('month', 1),\n",
       " ('compared', 1),\n",
       " ('lite', 1),\n",
       " ('sendgrid', 16),\n",
       " ('photo', 1),\n",
       " ('emailjet', 1),\n",
       " ('mention', 1),\n",
       " ('amazon', 2),\n",
       " ('theyre', 1),\n",
       " ('unfortunately', 1),\n",
       " ('sale', 2),\n",
       " ('drop', 1),\n",
       " ('line', 3),\n",
       " ('find', 2),\n",
       " ('overall', 1),\n",
       " ('wed', 3),\n",
       " ('mmm', 1),\n",
       " ('pmkt', 1),\n",
       " ('admon', 1),\n",
       " ('dist', 1),\n",
       " ('weve', 3),\n",
       " ('working', 2),\n",
       " ('general', 2),\n",
       " ('idea', 3),\n",
       " ('plan', 1),\n",
       " ('update', 2),\n",
       " ('posted', 1),\n",
       " ('friday', 3),\n",
       " ('yep', 2),\n",
       " ('glad', 3),\n",
       " ('help', 5),\n",
       " ('brainstorm', 1),\n",
       " ('needed', 3),\n",
       " ('troubleshoot', 1),\n",
       " ('official', 2),\n",
       " ('client', 5),\n",
       " ('inline', 1),\n",
       " ('doc', 2),\n",
       " ('info', 2),\n",
       " ('support', 5),\n",
       " ('team', 4),\n",
       " ('delivering', 1),\n",
       " ('hotmail', 1),\n",
       " ('currently', 2),\n",
       " ('w', 1),\n",
       " ('yeah', 3),\n",
       " ('cleaned', 1),\n",
       " ('delisted', 1),\n",
       " ('ip', 1),\n",
       " ('share', 1),\n",
       " ('alternative', 1),\n",
       " ('like', 12),\n",
       " ('looked', 2),\n",
       " ('year', 4),\n",
       " ('pricing', 5),\n",
       " ('api', 10),\n",
       " ('bit', 2),\n",
       " ('confusing', 1),\n",
       " ('straightened', 1),\n",
       " ('excellently', 1),\n",
       " ('realised', 1),\n",
       " ('second', 2),\n",
       " ('hitting', 2),\n",
       " ('add', 1),\n",
       " ('default', 1),\n",
       " ('header', 1),\n",
       " ('thank', 2),\n",
       " ('increase', 1),\n",
       " ('scalability', 1),\n",
       " ('decrease', 1),\n",
       " ('npm', 1),\n",
       " ('module', 5),\n",
       " ('what', 1),\n",
       " ('preferred', 1),\n",
       " ('way', 1),\n",
       " ('documenting', 1),\n",
       " ('bug', 1),\n",
       " ('tried', 1),\n",
       " ('refreshing', 1),\n",
       " ('link', 1),\n",
       " ('homepage', 1),\n",
       " ('go', 1),\n",
       " ('crash', 1),\n",
       " ('enquiring', 1),\n",
       " ('yeap', 1),\n",
       " ('that', 4),\n",
       " ('meant', 2),\n",
       " ('throttling', 2),\n",
       " ('get', 2),\n",
       " ('bulk', 1),\n",
       " ('increasing', 1),\n",
       " ('considerably', 1),\n",
       " ('tip', 1),\n",
       " ('warmup', 1),\n",
       " ('fwiw', 1),\n",
       " ('dumped', 1),\n",
       " ('postmark', 1),\n",
       " ('favor', 1),\n",
       " ('highly', 1),\n",
       " ('recommended', 1),\n",
       " ('ee', 1),\n",
       " ('u', 2),\n",
       " ('reach', 1),\n",
       " ('mailchimpmandrill', 1),\n",
       " ('user', 1),\n",
       " ('try', 2),\n",
       " ('workflow', 1),\n",
       " ('investigate', 1),\n",
       " ('looking', 8),\n",
       " ('sync', 1),\n",
       " ('unsubscribed', 1),\n",
       " ('address', 1),\n",
       " ('best', 4),\n",
       " ('production', 1),\n",
       " ('good', 9),\n",
       " ('system', 3),\n",
       " ('designed', 1),\n",
       " ('customized', 1),\n",
       " ('onetoone', 2),\n",
       " ('lik', 1),\n",
       " ('youd', 1),\n",
       " ('probably', 4),\n",
       " ('succes', 1),\n",
       " ('postman', 1),\n",
       " ('lost', 2),\n",
       " ('easily', 1),\n",
       " ('havent', 2),\n",
       " ('information', 1),\n",
       " ('depend', 2),\n",
       " ('simple', 1),\n",
       " ('equivalent', 1),\n",
       " ('url', 1),\n",
       " ('opening', 2),\n",
       " ('click', 1),\n",
       " ('etc', 2),\n",
       " ('custom', 1),\n",
       " ('algorithm', 1),\n",
       " ('inlining', 1),\n",
       " ('cs', 1),\n",
       " ('specifically', 1),\n",
       " ('migrate', 1),\n",
       " ('possibly', 1),\n",
       " ('exactly', 1),\n",
       " ('chance', 1),\n",
       " ('youll', 1),\n",
       " ('adding', 1),\n",
       " ('vero', 1),\n",
       " ('ive', 1),\n",
       " ('noticed', 1),\n",
       " ('lack', 1),\n",
       " ('attention', 1),\n",
       " ('secondary', 1),\n",
       " ('property', 1),\n",
       " ('ie', 1),\n",
       " ('tinyletter', 1),\n",
       " ('template', 10),\n",
       " ('design', 9),\n",
       " ('strategy', 9),\n",
       " ('implementation', 9),\n",
       " ('eshuy', 9),\n",
       " ('hi', 8),\n",
       " ('acces', 1),\n",
       " ('website', 2),\n",
       " ('h', 2),\n",
       " ('integrate', 4),\n",
       " ('grid', 3),\n",
       " ('ecommerce', 3),\n",
       " ('store', 3),\n",
       " ('push', 2),\n",
       " ('e', 2),\n",
       " ('webhook', 6),\n",
       " ('interspire', 3),\n",
       " ('processing', 5),\n",
       " ('inte', 1),\n",
       " ('php', 1),\n",
       " ('developer', 2),\n",
       " ('bullhorn', 1),\n",
       " ('experience', 2),\n",
       " ('elance', 1),\n",
       " ('job', 2),\n",
       " ('built', 1),\n",
       " ('listing', 1),\n",
       " ('customersupport', 1),\n",
       " ('geek', 1),\n",
       " ('cool', 2),\n",
       " ('based', 1),\n",
       " ('approach', 1),\n",
       " ('intersp', 1),\n",
       " ('ha', 1),\n",
       " ('question', 2),\n",
       " ('integrated', 1),\n",
       " ('wpmail', 1),\n",
       " ('sure', 1),\n",
       " ('gosh', 1),\n",
       " ('darn', 1),\n",
       " ('nice', 4),\n",
       " ('live', 4),\n",
       " ('come', 4),\n",
       " ('hear', 3),\n",
       " ('talk', 1),\n",
       " ('newsletter', 10),\n",
       " ('array', 2),\n",
       " ('portion', 1),\n",
       " ('solution', 1),\n",
       " ('area', 1),\n",
       " ('know', 7),\n",
       " ('point', 1),\n",
       " ('switch', 3),\n",
       " ('tell', 1),\n",
       " ('isnt', 1),\n",
       " ('check', 2),\n",
       " ('week', 4),\n",
       " ('including', 1),\n",
       " ('change', 2),\n",
       " ('easy', 2),\n",
       " ('sou', 1),\n",
       " ('ppl', 1),\n",
       " ('there', 1),\n",
       " ('emailsmo', 1),\n",
       " ('found', 1),\n",
       " ('knowledge', 1),\n",
       " ('base', 1),\n",
       " ('article', 1),\n",
       " ('inbound', 1),\n",
       " ('useful', 1),\n",
       " ('work', 2),\n",
       " ('biased', 1),\n",
       " ('recommendation', 2),\n",
       " ('coworker', 1),\n",
       " ('entrust', 1),\n",
       " ('handling', 1),\n",
       " ('pokemon', 1),\n",
       " ('guy', 1),\n",
       " ('wordpres', 6),\n",
       " ('holy', 2),\n",
       " ('shit', 4),\n",
       " ('estimated', 1),\n",
       " ('traffic', 1),\n",
       " ('net', 1),\n",
       " ('dev', 1),\n",
       " ('develop', 1),\n",
       " ('mamp', 1),\n",
       " ('pro', 1),\n",
       " ('setting', 1),\n",
       " ('light', 1),\n",
       " ('fiasco', 1),\n",
       " ('day', 1),\n",
       " ('inappropriate', 1),\n",
       " ('sexual', 1),\n",
       " ('joke', 1),\n",
       " ('competing', 1),\n",
       " ('called', 1),\n",
       " ('internetmarketing', 1),\n",
       " ('embarrassing', 1),\n",
       " ('going', 3),\n",
       " ('sleep', 1),\n",
       " ('quick', 1),\n",
       " ('psa', 1),\n",
       " ('awesome', 1),\n",
       " ('sendreceive', 1),\n",
       " ('love', 4),\n",
       " ('sorry', 1),\n",
       " ('designer', 1),\n",
       " ('swapping', 1),\n",
       " ('sōsh', 1),\n",
       " ('word', 1),\n",
       " ('warning', 1),\n",
       " ('triggered', 1),\n",
       " ('new', 9),\n",
       " ('product', 3),\n",
       " ('damn', 1),\n",
       " ('gmail', 1),\n",
       " ('asking', 1),\n",
       " ('web', 1),\n",
       " ('captcha', 1),\n",
       " ('automatic', 2),\n",
       " ('test', 1),\n",
       " ('mandill', 7),\n",
       " ('ruby', 2),\n",
       " ('gem', 1),\n",
       " ('interacting', 1),\n",
       " ('cli', 2),\n",
       " ('python', 2),\n",
       " ('library', 3),\n",
       " ('platform', 4),\n",
       " ('alternate', 2),\n",
       " ('sendmail', 1),\n",
       " ('transport', 1),\n",
       " ('world', 1),\n",
       " ('cloud', 1),\n",
       " ('computing', 1),\n",
       " ('mandrillapi', 2),\n",
       " ('mandrillrail', 1),\n",
       " ('rail', 1),\n",
       " ('measuring', 1),\n",
       " ('performance', 2),\n",
       " ('unraveled', 3),\n",
       " ('drupal', 3),\n",
       " ('lev', 3),\n",
       " ('t', 2),\n",
       " ('tsypin', 2),\n",
       " ('mo', 2),\n",
       " ('un', 1),\n",
       " ('pushing', 1),\n",
       " ('great', 3),\n",
       " ('tool', 1),\n",
       " ('confirmation', 1),\n",
       " ('forgot', 1),\n",
       " ('password', 2),\n",
       " ('notification', 2),\n",
       " ('affair', 1),\n",
       " ('transaction', 1),\n",
       " ('critsend', 1),\n",
       " ('started', 1),\n",
       " ('edocrco', 1),\n",
       " ('subscriber', 1),\n",
       " ('profile', 1),\n",
       " ('activity', 1),\n",
       " ('timeline', 1),\n",
       " ('aggregate', 1),\n",
       " ('engagement', 1),\n",
       " ('stat', 1),\n",
       " ('integratio', 1),\n",
       " ('parse', 1),\n",
       " ('partner', 1),\n",
       " ('bring', 1),\n",
       " ('power', 1),\n",
       " ('parsepowered', 1),\n",
       " ('progres', 1),\n",
       " ('sort', 1),\n",
       " ('thinking', 1),\n",
       " ('trying', 2),\n",
       " ('avoid', 1),\n",
       " ('psyched', 1),\n",
       " ('dropped', 1),\n",
       " ('price', 1),\n",
       " ('se', 1),\n",
       " ('competitor', 1),\n",
       " ('ready', 2),\n",
       " ('rock', 3),\n",
       " ('released', 1),\n",
       " ('couple', 1),\n",
       " ('escort', 1),\n",
       " ('postageapp', 1),\n",
       " ('fix', 2),\n",
       " ('rt', 3),\n",
       " ('ó', 1),\n",
       " ('suggestion', 2),\n",
       " ('tahdah', 1),\n",
       " ('wanted', 1),\n",
       " ('stage', 1),\n",
       " ('tomorrow', 2),\n",
       " ('autoplay', 1),\n",
       " ('dish', 1),\n",
       " ('building', 1),\n",
       " ('status', 1),\n",
       " ('stand', 3),\n",
       " ('sea', 1),\n",
       " ('green', 1),\n",
       " ('mark', 1),\n",
       " ('wisest', 1),\n",
       " ('jungle', 1),\n",
       " ('rafiki', 2),\n",
       " ('disney', 1),\n",
       " ('animal', 2),\n",
       " ('kingdom', 1),\n",
       " ('tdp', 1),\n",
       " ('digitalocean', 1),\n",
       " ('linode', 1),\n",
       " ('provisioning', 1),\n",
       " ('sunzi', 1),\n",
       " ('release', 1),\n",
       " ('note', 2),\n",
       " ('quota', 1),\n",
       " ('prioritization', 1),\n",
       " ('concern', 1),\n",
       " ('logo', 2),\n",
       " ('review', 1),\n",
       " ('application', 1),\n",
       " ('v', 1),\n",
       " ('validationerror', 1),\n",
       " ('google', 2),\n",
       " ('engine', 1),\n",
       " ('urlfetch', 1),\n",
       " ('impressed', 1),\n",
       " ('site', 1),\n",
       " ('spotles', 1),\n",
       " ('unifying', 2),\n",
       " ('datum', 2),\n",
       " ('beware', 1),\n",
       " ('hummingbird', 1),\n",
       " ('tiny', 1),\n",
       " ('cheetah', 1),\n",
       " ('head', 4),\n",
       " ('simplified', 1),\n",
       " ('reduced', 1),\n",
       " ('hooray', 1),\n",
       " ('whaaat', 1),\n",
       " ('didnt', 2),\n",
       " ('delivery', 1),\n",
       " ('thingy', 1),\n",
       " ('neat', 1),\n",
       " ('welcome', 1),\n",
       " ('reset', 1),\n",
       " ('payment', 1),\n",
       " ('mailgunmandrill', 1),\n",
       " ('zapier', 1),\n",
       " ('make', 1),\n",
       " ('comeback', 1),\n",
       " ('reproachful', 1),\n",
       " ('cover', 2),\n",
       " ('spillover', 1),\n",
       " ('drill', 2),\n",
       " ('picture', 1),\n",
       " ('holding', 1),\n",
       " ('somethin', 1),\n",
       " ('baby', 1),\n",
       " ('paignton', 1),\n",
       " ('zoo', 2),\n",
       " ('april', 1),\n",
       " ('cute', 1),\n",
       " ('mint', 1),\n",
       " ('condition', 1),\n",
       " ('maroon', 1),\n",
       " ('fray', 1),\n",
       " ('fat', 2),\n",
       " ('city', 1),\n",
       " ('strut', 1),\n",
       " ('jam', 1),\n",
       " ('soul', 2),\n",
       " ('train', 2),\n",
       " ('saw', 1),\n",
       " ('jacket', 2),\n",
       " ('impact', 1),\n",
       " ('board', 1),\n",
       " ('heard', 1),\n",
       " ('sound', 2),\n",
       " ('fan', 2),\n",
       " ('key', 1),\n",
       " ('band', 4),\n",
       " ('little', 2),\n",
       " ('chicano', 1),\n",
       " ('hot', 1),\n",
       " ('touch', 1),\n",
       " ('cock', 1),\n",
       " ('zach', 1),\n",
       " ('complaint', 1),\n",
       " ('direct', 1),\n",
       " ('tv', 1),\n",
       " ('stop', 1),\n",
       " ('showing', 2),\n",
       " ('game', 2),\n",
       " ('non', 1),\n",
       " ('lable', 1),\n",
       " ('toad', 1),\n",
       " ('lose', 1),\n",
       " ('silly', 2),\n",
       " ('understood', 1),\n",
       " ('cancre', 1),\n",
       " ('baboon', 1),\n",
       " ('bico', 1),\n",
       " ('venue', 1),\n",
       " ('coffee', 1),\n",
       " ('bean', 1),\n",
       " ('arrived', 1),\n",
       " ('glasgow', 1),\n",
       " ('horrible', 1),\n",
       " ('dangerou', 1),\n",
       " ('place', 2),\n",
       " ('drunken', 1),\n",
       " ('viciou', 1),\n",
       " ('git', 3),\n",
       " ('oh', 1),\n",
       " ('wait', 1),\n",
       " ('eve', 2),\n",
       " ('player', 2),\n",
       " ('hope', 1),\n",
       " ('record', 1),\n",
       " ('high', 2),\n",
       " ('quality', 1),\n",
       " ('audio', 2),\n",
       " ('plu', 1),\n",
       " ('faint', 1),\n",
       " ('ccp', 3),\n",
       " ('seagull', 1),\n",
       " ('background', 1),\n",
       " ('stream', 1),\n",
       " ('corner', 1),\n",
       " ('spice', 1),\n",
       " ('market', 1),\n",
       " ('demigod', 1),\n",
       " ('fusing', 1),\n",
       " ('poorlyunderstood', 1),\n",
       " ('body', 1),\n",
       " ('modification', 1),\n",
       " ('heinlein', 1),\n",
       " ('hed', 2),\n",
       " ('lot', 2),\n",
       " ('clone', 1),\n",
       " ('orgy', 1),\n",
       " ('zomg', 1),\n",
       " ('hiding', 1),\n",
       " ('fleet', 1),\n",
       " ('moon', 1),\n",
       " ('soo', 1),\n",
       " ('bad', 1),\n",
       " ('mean', 2),\n",
       " ('fundamentally', 1),\n",
       " ('different', 1),\n",
       " ('totally', 1),\n",
       " ('o', 4),\n",
       " ('wish', 2),\n",
       " ('long', 1),\n",
       " ('ah', 1),\n",
       " ('seen', 1),\n",
       " ('britain', 1),\n",
       " ('actually', 1),\n",
       " ('having', 1),\n",
       " ('summertime', 1),\n",
       " ('lol', 2),\n",
       " ('temporal', 1),\n",
       " ('shift', 1),\n",
       " ('ahh', 1),\n",
       " ('id', 2),\n",
       " ('save', 3),\n",
       " ('ff', 1),\n",
       " ('imma', 1),\n",
       " ('ce', 2),\n",
       " ('instead', 1),\n",
       " ('d', 1),\n",
       " ('read', 1),\n",
       " ('cheer', 1),\n",
       " ('proofing', 1),\n",
       " ('extra', 1),\n",
       " ('eye', 1),\n",
       " ('gameskinny', 1),\n",
       " ('editor', 1),\n",
       " ('sharp', 1),\n",
       " ('coming', 1),\n",
       " ('soon', 1),\n",
       " ('ship', 1),\n",
       " ('skin', 1),\n",
       " ('alliance', 1),\n",
       " ('throw', 1),\n",
       " ('entire', 1),\n",
       " ('bank', 1),\n",
       " ('haggis', 1),\n",
       " ('victor', 1),\n",
       " ('tweet', 1),\n",
       " ('wouldnt', 1),\n",
       " ('surprised', 1),\n",
       " ('typo', 1),\n",
       " ('gonna', 1),\n",
       " ('brain', 1),\n",
       " ('fully', 1),\n",
       " ('recover', 1),\n",
       " ('fanfest', 2),\n",
       " ('far', 1),\n",
       " ('n', 3),\n",
       " ('k', 3),\n",
       " ('correction', 1),\n",
       " ('true', 1),\n",
       " ('frigate', 1),\n",
       " ('cruiser', 1),\n",
       " ('model', 1),\n",
       " ('resubbed', 1),\n",
       " ('cant', 4),\n",
       " ('stay', 1),\n",
       " ('away', 1),\n",
       " ('mate', 1),\n",
       " ('mainly', 1),\n",
       " ('evil', 1),\n",
       " ('brainwashing', 1),\n",
       " ('technology', 1),\n",
       " ('effective', 1),\n",
       " ('talking', 1),\n",
       " ('abt', 1),\n",
       " ('amazing', 3),\n",
       " ('hair', 2),\n",
       " ('rally', 1),\n",
       " ('fortunately', 1),\n",
       " ('picked', 1),\n",
       " ('pink', 2),\n",
       " ('hat', 3),\n",
       " ('feedback', 1),\n",
       " ('b', 1),\n",
       " ('twitch', 1),\n",
       " ('winamp', 1),\n",
       " ('choice', 2),\n",
       " ('music', 3),\n",
       " ('cccp', 1),\n",
       " ('video', 11),\n",
       " ('playback', 1),\n",
       " ('wouldve', 1),\n",
       " ('included', 1),\n",
       " ('character', 2),\n",
       " ('limit', 1),\n",
       " ('prevented', 1),\n",
       " ('whatchu', 1),\n",
       " ('mandrillwow', 1),\n",
       " ('diplomacy', 1),\n",
       " ('got', 1),\n",
       " ('tshirt', 2),\n",
       " ('today', 5),\n",
       " ('came', 1),\n",
       " ('handwritten', 1),\n",
       " ('letter', 1),\n",
       " ('shop', 1),\n",
       " ('person', 2),\n",
       " ('quevaaaa', 1),\n",
       " ('went', 2),\n",
       " ('haha', 1),\n",
       " ('ll', 1),\n",
       " ('totoko', 1),\n",
       " ('ー', 1),\n",
       " ('ノ', 1),\n",
       " ('fashionable', 1),\n",
       " ('hairdresser', 1),\n",
       " ('wonderful', 1),\n",
       " ('ﾟ', 2),\n",
       " ('po', 1),\n",
       " ('pussy', 1),\n",
       " ('gone', 1),\n",
       " ('real', 1),\n",
       " ('castilla', 1),\n",
       " ('rotted', 1),\n",
       " ('disgustingly', 1),\n",
       " ('evolved', 1),\n",
       " ('gl', 1),\n",
       " ('p', 1),\n",
       " ('permission', 1),\n",
       " ('knit', 1),\n",
       " ('jayne', 2),\n",
       " ('anymore', 1),\n",
       " ('threat', 1),\n",
       " ('legal', 1),\n",
       " ('action', 1),\n",
       " ('happy', 2),\n",
       " ('follower', 1),\n",
       " ('outside', 1),\n",
       " ('universe', 1),\n",
       " ('rainbow', 1),\n",
       " ('christma', 1),\n",
       " ('nicolae', 1),\n",
       " ('original', 3),\n",
       " ('song', 6),\n",
       " ('santa', 1),\n",
       " ('ღ', 1),\n",
       " ('park', 1),\n",
       " ('star', 1),\n",
       " ('ty', 1),\n",
       " ('diverse', 1),\n",
       " ('group', 1),\n",
       " ('wbrooklyn', 1),\n",
       " ('root', 1),\n",
       " ('latten', 1),\n",
       " ('gunshy', 1),\n",
       " ('numbing', 1),\n",
       " ('seedtime', 1),\n",
       " ('crackbrained', 1),\n",
       " ('slicker', 1),\n",
       " ('added', 2),\n",
       " ('favorite', 2),\n",
       " ('megaman', 15),\n",
       " ('x', 20),\n",
       " ('spark', 25),\n",
       " ('acapella', 9),\n",
       " ('al', 1),\n",
       " ('carajo', 1),\n",
       " ('el', 1),\n",
       " ('mandrilloleoleoleoleoeleoleoeeoleoeleoleole', 1),\n",
       " ('ala', 1),\n",
       " ('hahahaha', 1),\n",
       " ('breastfeed', 1),\n",
       " ('fight', 2),\n",
       " ('sam', 2),\n",
       " ('syke', 2),\n",
       " ('regret', 1),\n",
       " ('forever', 1),\n",
       " ('hispanic', 1),\n",
       " ('raucou', 1),\n",
       " ('occupation', 1),\n",
       " ('near', 1),\n",
       " ('entertainment', 1),\n",
       " ('industry', 1),\n",
       " ('lodge', 1),\n",
       " ('hru', 1),\n",
       " ('reincarnated', 1),\n",
       " ('mandrillman', 1),\n",
       " ('expect', 1),\n",
       " ('arin', 1),\n",
       " ('trick', 1),\n",
       " ('wondering', 1),\n",
       " ('beat', 3),\n",
       " ('funk', 1),\n",
       " ('liked', 8),\n",
       " ('wear', 1),\n",
       " ('banjo', 1),\n",
       " ('believe', 1),\n",
       " ('meet', 2),\n",
       " ('chill', 1),\n",
       " ('penguin', 1),\n",
       " ('bafici', 1),\n",
       " ('pass', 1),\n",
       " ('mirageman', 1),\n",
       " ('woman', 1),\n",
       " ('submachine', 1),\n",
       " ('gun', 1),\n",
       " ('mandate', 1),\n",
       " ('cry', 1),\n",
       " ('creator', 1),\n",
       " ('attack', 1),\n",
       " ('producer', 1),\n",
       " ('sample', 1),\n",
       " ('knowwwwwwww', 1),\n",
       " ('aint', 1),\n",
       " ('pay', 1),\n",
       " ('bye', 1),\n",
       " ('son', 2),\n",
       " ('knock', 1),\n",
       " ('asshat', 1),\n",
       " ('philip', 1),\n",
       " ('treacy', 1),\n",
       " ('derrière', 1),\n",
       " ('fascinator', 1),\n",
       " ('sublime', 1),\n",
       " ('novel', 1),\n",
       " ('purple', 1),\n",
       " ('covered', 2),\n",
       " ('freckle', 1),\n",
       " ('essa', 1),\n",
       " ('mega', 6),\n",
       " ('man', 9),\n",
       " ('muito', 1),\n",
       " ('easiest', 1),\n",
       " ('bos', 1),\n",
       " ('junk', 1),\n",
       " ('spring', 1),\n",
       " ('cut', 1),\n",
       " ('listening', 1),\n",
       " ('shoot', 1),\n",
       " ('dy', 1),\n",
       " ('apparently', 1),\n",
       " ('leaf', 1),\n",
       " ('fencewalk', 2),\n",
       " ('stoopid', 1),\n",
       " ('fernando', 1),\n",
       " ('varga', 1),\n",
       " ('mexican', 1),\n",
       " ('pride', 1),\n",
       " ('mma', 1),\n",
       " ('goddamn', 1),\n",
       " ('suzie', 1),\n",
       " ('caesar', 1),\n",
       " ('listen', 1),\n",
       " ('goooooollllll', 1),\n",
       " ('del', 1),\n",
       " ('gameplay', 1),\n",
       " ('gostei', 1),\n",
       " ('um', 1),\n",
       " ('vídeo', 1),\n",
       " ('acapellla', 5),\n",
       " ('gues', 1),\n",
       " ('ernesto', 1),\n",
       " ('díaz', 1),\n",
       " ('butt', 2),\n",
       " ('lie', 1),\n",
       " ('male', 1),\n",
       " ('asset', 1),\n",
       " ('congo', 1),\n",
       " ('gorilla', 1),\n",
       " ('forest', 1),\n",
       " ('lion', 1),\n",
       " ('king', 1),\n",
       " ('hyena', 1),\n",
       " ('hahahahaha', 1),\n",
       " ('course', 1),\n",
       " ('inner', 1),\n",
       " ('toosh', 1),\n",
       " ('following', 1),\n",
       " ('chilly', 1),\n",
       " ('jamed', 1),\n",
       " ('funky', 2),\n",
       " ('mother', 1),\n",
       " ('evening', 1),\n",
       " ('musical', 1),\n",
       " ('god', 1),\n",
       " ('izasata', 1),\n",
       " ('mandrillstriker', 1),\n",
       " ('eldnoe', 1),\n",
       " ('roll', 2),\n",
       " ('whirlpool', 1),\n",
       " ('overran', 1),\n",
       " ('big', 2),\n",
       " ('flayer', 1),\n",
       " ('jammin', 1),\n",
       " ('christopher', 1),\n",
       " ('bream', 1),\n",
       " ('kaminsky', 1),\n",
       " ('exasperate', 1),\n",
       " ('bugging', 1),\n",
       " ('company', 1),\n",
       " ('patrovita', 1),\n",
       " ('reduce', 1),\n",
       " ('order', 1),\n",
       " ('ruff', 1),\n",
       " ('rocca', 1),\n",
       " ('le', 1),\n",
       " ('drawer', 1),\n",
       " ('aspiration', 1),\n",
       " ('flame', 1),\n",
       " ('mango', 1),\n",
       " ('meat', 2),\n",
       " ('gift', 1),\n",
       " ('classic', 3),\n",
       " ('pua', 1),\n",
       " ('artist', 1),\n",
       " ('he', 1),\n",
       " ('monkey', 3),\n",
       " ('theme', 4),\n",
       " ('capella', 2),\n",
       " ('spectacularlybearded', 1),\n",
       " ('smooth', 1),\n",
       " ('mcgroove', 1),\n",
       " ('feeling', 2),\n",
       " ('selection', 1),\n",
       " ('grace', 1),\n",
       " ('incredible', 1),\n",
       " ('squad', 1),\n",
       " ('halfmandrill', 1),\n",
       " ('halfmandelamy', 1),\n",
       " ('deep', 1),\n",
       " ('fela', 1),\n",
       " ('hoekstra', 1),\n",
       " ('vaneck', 1),\n",
       " ('cost', 1),\n",
       " ('buyer', 1),\n",
       " ('story', 1),\n",
       " ('peter', 1),\n",
       " ('friend', 1),\n",
       " ('kumba', 2),\n",
       " ('broken', 1),\n",
       " ('leg', 1),\n",
       " ('search', 1),\n",
       " ('gilipolla', 1),\n",
       " ('face', 1),\n",
       " ('remained', 1),\n",
       " ('hahaha', 1),\n",
       " ('raj', 1),\n",
       " ('shahrukh', 1),\n",
       " ('shogun', 1),\n",
       " ('immature', 1),\n",
       " ('silent', 1),\n",
       " ('endowed', 1),\n",
       " ('life', 1),\n",
       " ('despite', 1),\n",
       " ('blood', 1),\n",
       " ('brother', 1),\n",
       " ('unti', 1),\n",
       " ('xzw', 1),\n",
       " ('silk', 2),\n",
       " ('toma', 1),\n",
       " ('domecq', 1),\n",
       " ('straight', 1),\n",
       " ('loose', 1),\n",
       " ('voluptuou', 1),\n",
       " ('jump', 1),\n",
       " ('pair', 1),\n",
       " ('discover', 1),\n",
       " ('fabrication', 1),\n",
       " ('problem', 1),\n",
       " ('pinkie', 1),\n",
       " ('stekst', 1),\n",
       " ('written', 1),\n",
       " ('minority', 1),\n",
       " ('public', 1),\n",
       " ('enemy', 1),\n",
       " ('symphonic', 1),\n",
       " ('revolution', 1),\n",
       " ('taquipariu', 1),\n",
       " ('olha', 1),\n",
       " ('isso', 1),\n",
       " ('cartoon', 1),\n",
       " ('rfu', 1),\n",
       " ('online', 1),\n",
       " ('content', 1),\n",
       " ('spot', 1),\n",
       " ('win', 1),\n",
       " ('prize', 1),\n",
       " ('originally', 1),\n",
       " ('classed', 1),\n",
       " ('genu', 1),\n",
       " ('mandrillu', 1),\n",
       " ('devil', 1),\n",
       " ('dres', 1),\n",
       " ('half', 2),\n",
       " ('girl', 1),\n",
       " ('milwaukee', 1),\n",
       " ('county', 1),\n",
       " ('march', 1),\n",
       " ('heavy', 2),\n",
       " ('metal', 1),\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "big_list = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    l = row[\"split\"]\n",
    "    big_list = big_list + l\n",
    "\n",
    "counted = [*Counter(big_list).items()]\n",
    "counted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erase words that only occur once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counted = [s for s in counted if s[1] != 1]\n",
    "# counted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update dataframe with the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
      "C:\\Users\\fox\\AppData\\Local\\Temp\\ipykernel_33484\\988477245.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>good</th>\n",
       "      <th>language</th>\n",
       "      <th>translated</th>\n",
       "      <th>has url</th>\n",
       "      <th>has mandrill url</th>\n",
       "      <th>has @mandrill</th>\n",
       "      <th>has @youtube</th>\n",
       "      <th>has @mandrillapp</th>\n",
       "      <th>has @smoothmcgroove</th>\n",
       "      <th>...</th>\n",
       "      <th>_drum</th>\n",
       "      <th>_mandrillgetting</th>\n",
       "      <th>_mood</th>\n",
       "      <th>_rare</th>\n",
       "      <th>_break</th>\n",
       "      <th>_nottz</th>\n",
       "      <th>_feat</th>\n",
       "      <th>_pete</th>\n",
       "      <th>_turn</th>\n",
       "      <th>_mandrillmango</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[blog] Using Nullmailer and Mandrill for your ...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>[blog] Using Nullmailer and Mandrill for your ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[blog] Using Postfix and free Mandrill email s...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>[blog] Using Postfix and free Mandrill email s...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@aalbertson There are several reasons emails g...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>@aalbertson There are several reasons emails g...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@adrienneleigh I just switched it over to Mand...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>@adrienneleigh I just switched it over to Mand...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@ankeshk +1 to @mailchimp We use MailChimp for...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>@ankeshk +1 to @mailchimp We use MailChimp for...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Why Are Monkey Butts So Colorful?: Mandrill Wi...</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>Why Are Monkey Butts So Colorful?: Mandrill Wi...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>You can now experience the thrills of classic ...</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>You can now experience the thrills of classic ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>ジャンルごった煮のバンド、Mandrillの75年作！オススメはOddiseeがサンプリング...</td>\n",
       "      <td>False</td>\n",
       "      <td>ja</td>\n",
       "      <td>75 years of Mandrill, a boiled band of genre! ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>パーカッシヴなビートに重厚なベースやスペイシーなシンセ等が絡むB1が◎な80年の好作！シッカ...</td>\n",
       "      <td>False</td>\n",
       "      <td>ja</td>\n",
       "      <td>B1 with a heavy bass and Spacey synths on perc...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>最近ではNottz feat Pete Rock / Turn It Upでも使われていたレ...</td>\n",
       "      <td>False</td>\n",
       "      <td>ja</td>\n",
       "      <td>Rare Groove / Break Classic, which was also us...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 1056 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              original   good language  \\\n",
       "0    [blog] Using Nullmailer and Mandrill for your ...   True       en   \n",
       "1    [blog] Using Postfix and free Mandrill email s...   True       en   \n",
       "2    @aalbertson There are several reasons emails g...   True       en   \n",
       "3    @adrienneleigh I just switched it over to Mand...   True       en   \n",
       "4    @ankeshk +1 to @mailchimp We use MailChimp for...   True       en   \n",
       "..                                                 ...    ...      ...   \n",
       "295  Why Are Monkey Butts So Colorful?: Mandrill Wi...  False       en   \n",
       "296  You can now experience the thrills of classic ...  False       en   \n",
       "297  ジャンルごった煮のバンド、Mandrillの75年作！オススメはOddiseeがサンプリング...  False       ja   \n",
       "298  パーカッシヴなビートに重厚なベースやスペイシーなシンセ等が絡むB1が◎な80年の好作！シッカ...  False       ja   \n",
       "299  最近ではNottz feat Pete Rock / Turn It Upでも使われていたレ...  False       ja   \n",
       "\n",
       "                                            translated  has url  \\\n",
       "0    [blog] Using Nullmailer and Mandrill for your ...     True   \n",
       "1    [blog] Using Postfix and free Mandrill email s...     True   \n",
       "2    @aalbertson There are several reasons emails g...     True   \n",
       "3    @adrienneleigh I just switched it over to Mand...    False   \n",
       "4    @ankeshk +1 to @mailchimp We use MailChimp for...    False   \n",
       "..                                                 ...      ...   \n",
       "295  Why Are Monkey Butts So Colorful?: Mandrill Wi...     True   \n",
       "296  You can now experience the thrills of classic ...     True   \n",
       "297  75 years of Mandrill, a boiled band of genre! ...     True   \n",
       "298  B1 with a heavy bass and Spacey synths on perc...     True   \n",
       "299  Rare Groove / Break Classic, which was also us...     True   \n",
       "\n",
       "     has mandrill url  has @mandrill  has @youtube  has @mandrillapp  \\\n",
       "0               False          False         False             False   \n",
       "1               False          False         False             False   \n",
       "2                True          False         False             False   \n",
       "3               False          False         False             False   \n",
       "4               False          False         False             False   \n",
       "..                ...            ...           ...               ...   \n",
       "295             False          False         False             False   \n",
       "296             False          False         False             False   \n",
       "297             False          False         False             False   \n",
       "298             False          False         False             False   \n",
       "299             False          False         False             False   \n",
       "\n",
       "     has @smoothmcgroove  ...  _drum  _mandrillgetting  _mood  _rare _break  \\\n",
       "0                  False  ...  False             False  False  False  False   \n",
       "1                  False  ...  False             False  False  False  False   \n",
       "2                  False  ...  False             False  False  False  False   \n",
       "3                  False  ...  False             False  False  False  False   \n",
       "4                  False  ...  False             False  False  False  False   \n",
       "..                   ...  ...    ...               ...    ...    ...    ...   \n",
       "295                False  ...  False             False  False  False  False   \n",
       "296                False  ...  False             False  False  False  False   \n",
       "297                False  ...  False             False  False  False  False   \n",
       "298                False  ...   True              True   True  False  False   \n",
       "299                False  ...  False             False  False   True   True   \n",
       "\n",
       "     _nottz  _feat  _pete  _turn  _mandrillmango  \n",
       "0     False  False  False  False           False  \n",
       "1     False  False  False  False           False  \n",
       "2     False  False  False  False           False  \n",
       "3     False  False  False  False           False  \n",
       "4     False  False  False  False           False  \n",
       "..      ...    ...    ...    ...             ...  \n",
       "295   False  False  False  False           False  \n",
       "296   False  False  False  False           False  \n",
       "297   False  False  False  False           False  \n",
       "298   False  False  False  False           False  \n",
       "299    True   True   True   True            True  \n",
       "\n",
       "[300 rows x 1056 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def has_word(word, row):\n",
    "    splt = row[\"split\"]\n",
    "    return word in splt\n",
    "\n",
    "for word, count in counted:\n",
    "    df[f\"_{word}\"] = df.apply(lambda row : has_word(word, row), axis = 1)\n",
    "\n",
    "df.to_csv(path_or_buf=\"data/test.csv\", sep=';')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>good</th>\n",
       "      <th>language</th>\n",
       "      <th>translated</th>\n",
       "      <th>has url</th>\n",
       "      <th>has mandrill url</th>\n",
       "      <th>has @mandrill</th>\n",
       "      <th>has @youtube</th>\n",
       "      <th>has @mandrillapp</th>\n",
       "      <th>has @smoothmcgroove</th>\n",
       "      <th>...</th>\n",
       "      <th>_drum</th>\n",
       "      <th>_mandrillgetting</th>\n",
       "      <th>_mood</th>\n",
       "      <th>_rare</th>\n",
       "      <th>_break</th>\n",
       "      <th>_nottz</th>\n",
       "      <th>_feat</th>\n",
       "      <th>_pete</th>\n",
       "      <th>_turn</th>\n",
       "      <th>_mandrillmango</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From Coworker about using Mandrill:  \"I would ...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>From Coworker about using Mandrill:  \"I would ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@mandrillapp tried refreshing, the link (line ...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>@mandrillapp tried refreshing, the link (line ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This week: move TDP to either DigitalOcean or ...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>This week: move TDP to either DigitalOcean or ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this little girl is a mandrill. Milwaukee Coun...</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>this little girl is a mandrill. Milwaukee Coun...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Job Integrate Mandrill or Send Grid with Ecom...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>#Job Integrate Mandrill or Send Grid with Ecom...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>@As_TomasRoncero a la mierda el mandrill tocat...</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "      <td>@As_tomasroncero to shit the mandrill touch yo...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Le mandrill se casse #instantchiale</td>\n",
       "      <td>False</td>\n",
       "      <td>it</td>\n",
       "      <td>Le mandrill if #ininintantchiale drawers</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>@EricCandino They're unfortunately not for sal...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>@EricCandino They're unfortunately not for sal...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>@mandrill @Freebooted. I want to say Heinlein ...</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>@mandrill @Freebooted. I want to say Heinlein ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>@Tamiyadd If you haven't already, can you subm...</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>@Tamiyadd If you haven't already, can you subm...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 1056 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              original   good language  \\\n",
       "0    From Coworker about using Mandrill:  \"I would ...   True       en   \n",
       "1    @mandrillapp tried refreshing, the link (line ...   True       en   \n",
       "2    This week: move TDP to either DigitalOcean or ...   True       en   \n",
       "3    this little girl is a mandrill. Milwaukee Coun...  False       en   \n",
       "4    #Job Integrate Mandrill or Send Grid with Ecom...   True       en   \n",
       "..                                                 ...    ...      ...   \n",
       "295  @As_TomasRoncero a la mierda el mandrill tocat...  False       es   \n",
       "296                Le mandrill se casse #instantchiale  False       it   \n",
       "297  @EricCandino They're unfortunately not for sal...   True       en   \n",
       "298  @mandrill @Freebooted. I want to say Heinlein ...  False       en   \n",
       "299  @Tamiyadd If you haven't already, can you subm...   True       en   \n",
       "\n",
       "                                            translated  has url  \\\n",
       "0    From Coworker about using Mandrill:  \"I would ...    False   \n",
       "1    @mandrillapp tried refreshing, the link (line ...     True   \n",
       "2    This week: move TDP to either DigitalOcean or ...    False   \n",
       "3    this little girl is a mandrill. Milwaukee Coun...     True   \n",
       "4    #Job Integrate Mandrill or Send Grid with Ecom...     True   \n",
       "..                                                 ...      ...   \n",
       "295  @As_tomasroncero to shit the mandrill touch yo...    False   \n",
       "296           Le mandrill if #ininintantchiale drawers    False   \n",
       "297  @EricCandino They're unfortunately not for sal...     True   \n",
       "298  @mandrill @Freebooted. I want to say Heinlein ...    False   \n",
       "299  @Tamiyadd If you haven't already, can you subm...     True   \n",
       "\n",
       "     has mandrill url  has @mandrill  has @youtube  has @mandrillapp  \\\n",
       "0               False          False         False             False   \n",
       "1                True          False         False              True   \n",
       "2               False          False         False             False   \n",
       "3               False          False         False             False   \n",
       "4               False          False         False             False   \n",
       "..                ...            ...           ...               ...   \n",
       "295             False          False         False             False   \n",
       "296             False          False         False             False   \n",
       "297              True          False         False             False   \n",
       "298             False           True         False             False   \n",
       "299              True          False         False             False   \n",
       "\n",
       "     has @smoothmcgroove  ...  _drum  _mandrillgetting  _mood  _rare _break  \\\n",
       "0                  False  ...  False             False  False  False  False   \n",
       "1                  False  ...  False             False  False  False  False   \n",
       "2                  False  ...  False             False  False  False  False   \n",
       "3                  False  ...  False             False  False  False  False   \n",
       "4                  False  ...  False             False  False  False  False   \n",
       "..                   ...  ...    ...               ...    ...    ...    ...   \n",
       "295                False  ...  False             False  False  False  False   \n",
       "296                False  ...  False             False  False  False  False   \n",
       "297                False  ...  False             False  False  False  False   \n",
       "298                False  ...  False             False  False  False  False   \n",
       "299                False  ...  False             False  False  False  False   \n",
       "\n",
       "     _nottz  _feat  _pete  _turn  _mandrillmango  \n",
       "0     False  False  False  False           False  \n",
       "1     False  False  False  False           False  \n",
       "2     False  False  False  False           False  \n",
       "3     False  False  False  False           False  \n",
       "4     False  False  False  False           False  \n",
       "..      ...    ...    ...    ...             ...  \n",
       "295   False  False  False  False           False  \n",
       "296   False  False  False  False           False  \n",
       "297   False  False  False  False           False  \n",
       "298   False  False  False  False           False  \n",
       "299   False  False  False  False           False  \n",
       "\n",
       "[300 rows x 1056 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier\n",
    "Naive Bayes Classifier is a simplification of the more accurate Bayes Classifier. It assumes that all the attributes in the dataset are independent of each other. That assumption allows us to make the following simplification:\n",
    "$$\n",
    "Pr(X | C_i) = Pr(x_1, \\dots, x_k, \\dots, x_n | C_i) = \\prod_{k = 1}^n Pr(x_k | C_i)\n",
    "$$\n",
    "The goal is to solve the following equation\n",
    "$$\n",
    "C^* = \\arg \\max_{C_i : i \\geq 1} (Pr(X|C_i) \\cdot Pr(C_i)) = \\arg \\max_{C_i : i \\geq 1} (Pr(C_i) \\prod_{k = 1}^n Pr(x_k | C_i))\n",
    "$$\n",
    "In the next step we estimate $Pr(C_i)$ and $Pr(x_k | C_i)$ \n",
    "$$\n",
    "Pr(C_i) = \\frac{|C_i|}{|Z|}\n",
    "$$\n",
    "$$\n",
    "Pr(x_k | C_i) = \\frac{|C_i^{x_k}|}{|C_i|}\n",
    "$$\n",
    "Some situations will yield the null probability and thus we need to use the Laplace's smoothing to account for that.\n",
    "$$\n",
    "Pr(C_i) = \\frac{|C_i| + \\lambda }{|Z| + \\lambda \\cdot m} \\quad i = 1, \\dots, m\n",
    "$$\n",
    "$$\n",
    "Pr(x_k | C_i) = \\frac{|C_i^{x_k}| + \\lambda}{|C_i| + \\lambda \\cdot |x_k|} \\quad i = 1, \\dots, n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "class NaiveBayessClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, laplace_smoothing = False, verbose = True):\n",
    "        self.laplace_smoothing = laplace_smoothing\n",
    "        self.verbose = verbose\n",
    "    def fit(self, X, y, categories = None):\n",
    "        if categories == None:\n",
    "            ohe = OneHotEncoder()\n",
    "            ohe.fit(X)\n",
    "            self.x_categories_ = ohe.categories_.copy()\n",
    "        else:\n",
    "            self.x_categories_ = categories\n",
    "\n",
    "        ohe = OneHotEncoder()\n",
    "        ohe.fit(pd.DataFrame(y))\n",
    "        self.y_categories = ohe.categories_[0].copy()\n",
    "\n",
    "        og_columns = X.columns.copy()\n",
    "\n",
    "        self.prob_data = {}\n",
    "        self.prob_y = {}\n",
    "\n",
    "        for p in self.y_categories:\n",
    "            count = len(y)\n",
    "            cat_count = 0\n",
    "            for row in y.to_numpy():\n",
    "                if(row == p):\n",
    "                    cat_count = cat_count + 1    \n",
    "            \n",
    "            prob = 0.0\n",
    "            if self.laplace_smoothing == False:\n",
    "                prob = float(cat_count) / float(count)\n",
    "            else:\n",
    "                m = len(self.y_categories) \n",
    "                prob = (float(cat_count) + 1.0) / (float(count) + m)\n",
    "\n",
    "            self.prob_y[f\"{p}\"] = prob\n",
    "\n",
    "            self.prob_data[f\"{p}\"] = {}\n",
    "            for c in og_columns:\n",
    "                for cat in self.x_categories_[X.columns.get_loc(c)]:\n",
    "                    count = 0\n",
    "                    cat_count = 0\n",
    "                    for index, row in X.iterrows():\n",
    "                        if(y.to_numpy()[int(index)] != p):\n",
    "                            continue\n",
    "                        count = count + 1\n",
    "                        if(row[c] == cat):\n",
    "                            cat_count += 1\n",
    "\n",
    "                    prob = 0.0\n",
    "                    if self.laplace_smoothing == False:\n",
    "                        prob = float(cat_count) / float(count)\n",
    "                    else:\n",
    "                        m = len(self.x_categories_[X.columns.get_loc(c)])\n",
    "                        prob = (float(cat_count) + 1) / (float(count) + m)\n",
    "\n",
    "                    self.prob_data[f\"{p}\"][f\"{c}={cat}\"] = prob\n",
    "\n",
    "                    None\n",
    "\n",
    "        if self.verbose:\n",
    "            print(self.prob_data)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        results = np.array([*range(0, len(X))], dtype=object)\n",
    "        for i, row in X.iterrows():\n",
    "            v = {}\n",
    "            for y_cat in self.y_categories:\n",
    "                v[y_cat] = self.prob_y[f\"{y_cat}\"] \n",
    "                out = f\"{y_cat} : ({y_cat}){v[y_cat]} * \"\n",
    "                for x_label in X.columns:\n",
    "                    d = self.prob_data[f'{y_cat}']\n",
    "                    f = self.prob_data[f\"{y_cat}\"][f\"{x_label}={row[x_label]}\"]\n",
    "                    v[y_cat] = v[y_cat] * f\n",
    "                    out = out + f\" {x_label}({f}) *\"\n",
    "            \n",
    "                out = out[:-1]\n",
    "                out = out + f\"= {v[y_cat]}\"\n",
    "                if self.verbose:\n",
    "                    print(out)\n",
    "            \n",
    "\n",
    "            m = max(v, key=v.get)\n",
    "            results[i] = m\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"max(p) = {m}\")\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = df.drop([\"original\", \"good\", \"translated\", \"split\"], axis=1)\n",
    "def translate(row):\n",
    "    if row[\"good\"]:\n",
    "        return \"good\"\n",
    "    return \"bad\"\n",
    "\n",
    "Y = df[[\"good\"]].apply(translate, axis=1).copy()\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "splits = model_selection.train_test_split(X, Y, test_size=.2, random_state=0)\n",
    "X_train, X_test, y_train, y_test = splits\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NaiveBayessClassifier(laplace_smoothing=True, verbose=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NaiveBayessClassifier</label><div class=\"sk-toggleable__content\"><pre>NaiveBayessClassifier(laplace_smoothing=True, verbose=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NaiveBayessClassifier(laplace_smoothing=True, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe.fit(X)\n",
    "cats = ohe.categories_.copy()\n",
    "\n",
    "kNN = NaiveBayessClassifier(laplace_smoothing=True, verbose = False)\n",
    "kNN.fit(X_train, y_train, categories=cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayessian score : 0.9833333333333333\n",
      "Bayessian score : 0.9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "for x, y in [(X_train, y_train)]: \n",
    "    Y_pred = kNN.predict(x)\n",
    "    score = accuracy_score(y, Y_pred)\n",
    "\n",
    "    print(f\"Bayessian score : {score}\")\n",
    "    mat = confusion_matrix(y, Y_pred)\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(\n",
    "        y_true = y, \n",
    "        y_pred = Y_pred,\n",
    "        cmap=plt.cm.Blues,\n",
    "        labels=kNN.y_categories,\n",
    "        ax = axs[0]\n",
    "    )\n",
    "\n",
    "    disp.ax_.set_title(f\"Confusion Matrix\\nTrain Data\\nAccuracy = {score}\")\n",
    "    \n",
    "for x, y in [(X_test, y_test)]: \n",
    "    Y_pred = kNN.predict(x)\n",
    "    score = accuracy_score(y, Y_pred)\n",
    "\n",
    "    print(f\"Bayessian score : {score}\")\n",
    "    mat = confusion_matrix(y, Y_pred)\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(\n",
    "        y_true = y, \n",
    "        y_pred = Y_pred,\n",
    "        cmap=plt.cm.Blues,\n",
    "        labels=kNN.y_categories,\n",
    "        ax = axs[1]\n",
    "    )\n",
    "\n",
    "    disp.ax_.set_title(f\"Confusion Matrix\\nTest Data\\nAccuracy = {score}\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
